"use strict";(globalThis.webpackChunkphysical_ai_platform_frontend=globalThis.webpackChunkphysical_ai_platform_frontend||[]).push([[7160],{2222:(r,n,e)=>{e.r(n),e.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3/week-1-introduction/3-4-isaac-sim-practical-exercises","title":"3.4: Isaac Sim Practical Exercises","description":"Overview","source":"@site/docs/module-3/week-1-introduction/3-4-isaac-sim-practical-exercises.md","sourceDirName":"module-3/week-1-introduction","slug":"/module-3/week-1-introduction/3-4-isaac-sim-practical-exercises","permalink":"/docs/module-3/week-1-introduction/3-4-isaac-sim-practical-exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/noor-ana/physical-ai-platform/tree/main/docs/module-3/week-1-introduction/3-4-isaac-sim-practical-exercises.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"difficulty":"intermediate"},"sidebar":"tutorialSidebar","previous":{"title":"3.3: Isaac Sim Basics and Robotics Concepts","permalink":"/docs/module-3/week-1-introduction/3-3-isaac-sim-basics-robotics"},"next":{"title":"Week 2: Isaac ROS Basics","permalink":"/docs/module-3/week-2-isaac-ros-basics/2-1-introduction-to-isaac-ros"}}');var i=e(4848),a=e(8453);const s={sidebar_position:4,difficulty:"intermediate"},o="3.4: Isaac Sim Practical Exercises",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Exercise 1: Complete Robot Simulation Environment",id:"exercise-1-complete-robot-simulation-environment",level:2},{value:"Objective",id:"objective",level:3},{value:"Step 1: Create Workspace Structure",id:"step-1-create-workspace-structure",level:3},{value:"Step 2: Create Robot Configuration",id:"step-2-create-robot-configuration",level:3},{value:"Step 3: Create Sensor Integration Script",id:"step-3-create-sensor-integration-script",level:3},{value:"Exercise 2: Robot Navigation in Isaac Sim",id:"exercise-2-robot-navigation-in-isaac-sim",level:2},{value:"Objective",id:"objective-1",level:3},{value:"Exercise 3: Advanced Sensor Processing",id:"exercise-3-advanced-sensor-processing",level:2},{value:"Objective",id:"objective-2",level:3},{value:"Exercise 4: Isaac Sim Extension Development",id:"exercise-4-isaac-sim-extension-development",level:2},{value:"Objective",id:"objective-3",level:3},{value:"Exercise 5: Running the Exercises",id:"exercise-5-running-the-exercises",level:2},{value:"Running Instructions",id:"running-instructions",level:3},{value:"Summary",id:"summary",level:2}];function p(r){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...r.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"34-isaac-sim-practical-exercises",children:"3.4: Isaac Sim Practical Exercises"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This submodule provides hands-on exercises to apply the Isaac Sim concepts learned in the previous submodules. You'll create complete robotics simulation scenarios, implement robot control, work with sensors in Isaac Sim, and integrate everything with ROS 2."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this submodule, you will:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Build a complete simulation environment with robots and sensors in Isaac Sim"}),"\n",(0,i.jsx)(n.li,{children:"Implement robot navigation and control in Isaac Sim"}),"\n",(0,i.jsx)(n.li,{children:"Work with Isaac Sim's advanced sensor models"}),"\n",(0,i.jsx)(n.li,{children:"Create custom Isaac Sim extensions"}),"\n",(0,i.jsx)(n.li,{children:"Integrate Isaac Sim with ROS 2 navigation stack"}),"\n",(0,i.jsx)(n.li,{children:"Debug common Isaac Sim issues and optimize performance"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"exercise-1-complete-robot-simulation-environment",children:"Exercise 1: Complete Robot Simulation Environment"}),"\n",(0,i.jsx)(n.h3,{id:"objective",children:"Objective"}),"\n",(0,i.jsx)(n.p,{children:"Create a complete simulation environment in Isaac Sim with a robot, environment, and basic ROS 2 integration."}),"\n",(0,i.jsx)(n.h3,{id:"step-1-create-workspace-structure",children:"Step 1: Create Workspace Structure"}),"\n",(0,i.jsx)(n.p,{children:"First, let's create the necessary structure for our Isaac Sim exercises:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Create a directory for Isaac Sim exercises\r\nmkdir -p ~/isaac_sim_exercises/{robots,worlds,scripts,config}\r\ncd ~/isaac_sim_exercises\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-create-robot-configuration",children:"Step 2: Create Robot Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Create a Python script to set up our robot in Isaac Sim (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/setup_robot.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nComplete robot setup script for Isaac Sim\r\n"""\r\n\r\nimport sys\r\nimport os\r\n\r\n# Add Isaac Sim Python paths\r\nisaac_sim_path = os.environ.get(\'ISAAC_SIM_PATH\')\r\nif isaac_sim_path:\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'python\'))\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'kit\'))\r\n\r\n# Import Isaac Sim modules\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.prims import create_prim, get_prim_at_path\r\nfrom omni.isaac.core.utils.stage import get_stage_units\r\nfrom omni.isaac.core.materials import PreviewSurface\r\nfrom pxr import Gf, UsdGeom\r\nimport numpy as np\r\n\r\n\r\nclass IsaacSimExerciseRobot:\r\n    """Class to manage our exercise robot in Isaac Sim"""\r\n    \r\n    def __init__(self):\r\n        """Initialize the exercise robot"""\r\n        self.world = None\r\n        self.robot = None\r\n        self.robot_path = "/World/ExerciseRobot"\r\n        self.name = "exercise_robot"\r\n        \r\n    def setup_world(self):\r\n        """Set up the simulation world"""\r\n        print("Setting up the simulation world...")\r\n        \r\n        # Create the world with 1m units\r\n        self.world = World(stage_units_in_meters=1.0)\r\n        \r\n        # Add default ground plane\r\n        self.world.scene.add_default_ground_plane()\r\n        \r\n        print("\u2713 World setup complete")\r\n        \r\n    def add_environment_objects(self):\r\n        """Add environment objects to the scene"""\r\n        print("Adding environment objects...")\r\n        \r\n        # Add a table\r\n        create_prim(\r\n            prim_path="/World/Table",\r\n            prim_type="Cuboid",\r\n            position=[2, 0, 0.5],\r\n            scale=[1.5, 1, 0.05]\r\n        )\r\n        \r\n        # Add a box on the table\r\n        create_prim(\r\n            prim_path="/World/Table/Box",\r\n            prim_type="Cube",\r\n            position=[2, 0, 0.75],\r\n            scale=[0.3, 0.3, 0.3]\r\n        )\r\n        \r\n        # Add a wall\r\n        create_prim(\r\n            prim_path="/World/Wall",\r\n            prim_type="Cuboid",\r\n            position=[0, 3, 1],\r\n            scale=[5, 0.1, 2],\r\n            orientation=[0, 0, 0.707, 0.707]  # 90-degree rotation around Z\r\n        )\r\n        \r\n        # Create a simple room-like environment\r\n        create_prim(\r\n            prim_path="/World/Wall1",\r\n            prim_type="Cuboid",\r\n            position=[3, 0, 1],\r\n            scale=[0.1, 5, 2]\r\n        )\r\n        \r\n        print("\u2713 Environment objects added")\r\n    \r\n    def add_robot(self):\r\n        """Add the robot to the simulation"""\r\n        print("Adding robot to simulation...")\r\n        \r\n        try:\r\n            # Try to use a default robot asset\r\n            assets_root_path = get_assets_root_path()\r\n            if assets_root_path:\r\n                robot_usd_path = assets_root_path + "/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd"\r\n                \r\n                self.robot = self.world.scene.add(\r\n                    Robot(\r\n                        prim_path=self.robot_path,\r\n                        name=self.name,\r\n                        usd_path=robot_usd_path,\r\n                        position=[0, 0, 0.1],\r\n                        orientation=[0, 0, 0, 1]\r\n                    )\r\n                )\r\n                print(f"\u2713 Robot added from asset: {robot_usd_path}")\r\n            else:\r\n                print("\u2717 Could not find Isaac Sim assets, creating a basic robot")\r\n                # Fallback: Create a simple robot using basic prims\r\n                self.create_basic_robot()\r\n                \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to add robot from asset: {e}")\r\n            # Fallback: Create a simple robot\r\n            self.create_basic_robot()\r\n    \r\n    def create_basic_robot(self):\r\n        """Create a basic robot if assets are not available"""\r\n        print("Creating basic robot...")\r\n        \r\n        # Create robot root\r\n        create_prim(\r\n            prim_path=self.robot_path,\r\n            prim_type="Xform",\r\n            position=[0, 0, 0.5]\r\n        )\r\n        \r\n        # Create robot base\r\n        create_prim(\r\n            prim_path=f"{self.robot_path}/Base",\r\n            prim_type="Cylinder",\r\n            position=[0, 0, 0],\r\n            scale=[0.2, 0.2, 0.2]\r\n        )\r\n        \r\n        # Create wheels\r\n        create_prim(\r\n            prim_path=f"{self.robot_path}/LeftWheel",\r\n            prim_type="Cylinder",\r\n            position=[0, 0.15, 0],\r\n            scale=[0.1, 0.1, 0.05]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path=f"{self.robot_path}/RightWheel",\r\n            prim_type="Cylinder",\r\n            position=[0, -0.15, 0],\r\n            scale=[0.1, 0.1, 0.05]\r\n        )\r\n        \r\n        print("\u2713 Basic robot created")\r\n    \r\n    def add_sensors(self):\r\n        """Add sensors to the robot"""\r\n        print("Adding sensors to the robot...")\r\n        \r\n        # Add a camera sensor\r\n        try:\r\n            from omni.isaac.sensor import Camera\r\n            \r\n            camera = Camera(\r\n                prim_path=f"{self.robot_path}/FrontCamera",\r\n                position=np.array([0.1, 0, 0.1]),  # Position relative to robot\r\n                frequency=30,\r\n                resolution=(640, 480)\r\n            )\r\n            camera.initialize()\r\n            \r\n            print("\u2713 Camera sensor added")\r\n        except Exception as e:\r\n            print(f"\u2717 Failed to add camera: {e}")\r\n        \r\n        # Add LiDAR sensor\r\n        try:\r\n            from omni.isaac.sensor import RotatingLidarPhysX\r\n            \r\n            lidar = RotatingLidarPhysX(\r\n                prim_path=f"{self.robot_path}/Lidar",\r\n                translation=np.array([0.05, 0, 0.2]),\r\n                config="Example_Rotary",\r\n                depth_range=10.0,\r\n                horizontal_resolution=0.25,\r\n                vertical_resolution=0.5,\r\n                horizontal_fov=360,\r\n                vertical_fov=30,\r\n                rotation_frequency=10,\r\n                samples_per_scan=1440\r\n            )\r\n            lidar.initialize()\r\n            \r\n            print("\u2713 LiDAR sensor added")\r\n        except Exception as e:\r\n            print(f"\u2717 Failed to add LiDAR: {e}")\r\n        \r\n        # Add IMU sensor\r\n        try:\r\n            from omni.isaac.core.sensors import Imu\r\n            \r\n            imu = Imu(\r\n                prim_path=f"{self.robot_path}/Imu",\r\n                position=np.array([0.0, 0.0, 0.1]),\r\n                orientation=np.array([0, 0, 0, 1])\r\n            )\r\n            imu.initialize()\r\n            \r\n            print("\u2713 IMU sensor added")\r\n        except Exception as e:\r\n            print(f"\u2717 Failed to add IMU: {e}")\r\n    \r\n    def setup_physics(self):\r\n        """Configure physics properties for the robot"""\r\n        print("Setting up physics properties...")\r\n        \r\n        # Set up basic physics for robot components\r\n        try:\r\n            from omni.isaac.core.utils.prims import setRigidBodyProperties\r\n            from omni.isaac.core.utils.prims import setStaticColliderProperties\r\n            \r\n            # Set properties for robot base\r\n            base_path = f"{self.robot_path}/Base"\r\n            setRigidBodyProperties(\r\n                prim_path=base_path,\r\n                mass=10.0,\r\n                linear_damping=0.05,\r\n                angular_damping=0.1\r\n            )\r\n            \r\n            setStaticColliderProperties(\r\n                prim_path=base_path,\r\n                approximation_shape="convexHull"\r\n            )\r\n            \r\n            print("\u2713 Physics properties configured")\r\n        except Exception as e:\r\n            print(f"\u2717 Failed to configure physics: {e}")\r\n    \r\n    def run_simulation(self):\r\n        """Run the complete simulation"""\r\n        print("Starting simulation...")\r\n        \r\n        # Reset the world to initialize all objects\r\n        self.world.reset()\r\n        \r\n        print("\u2713 World reset complete")\r\n        \r\n        # Run simulation for a few steps\r\n        for i in range(100):\r\n            self.world.step(render=True)\r\n            \r\n            if i % 20 == 0:\r\n                # Print robot position periodically\r\n                if self.robot:\r\n                    pos, quat = self.robot.get_world_pose()\r\n                    print(f"Step {i}: Robot position: [{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]")\r\n        \r\n        print("\u2713 Simulation completed")\r\n        \r\n        # Cleanup\r\n        self.world.clear()\r\n        print("\u2713 World cleared")\r\n\r\n\r\ndef main():\r\n    """Main function to run the exercise"""\r\n    print("="*60)\r\n    print("Isaac Sim Exercise: Complete Robot Setup")\r\n    print("="*60)\r\n    \r\n    # Create and run the exercise robot\r\n    exercise_robot = IsaacSimExerciseRobot()\r\n    \r\n    try:\r\n        exercise_robot.setup_world()\r\n        exercise_robot.add_environment_objects()\r\n        exercise_robot.add_robot()\r\n        exercise_robot.add_sensors()\r\n        exercise_robot.setup_physics()\r\n        exercise_robot.run_simulation()\r\n        \r\n        print("\\n\u2713 Exercise complete successfully!")\r\n        \r\n    except Exception as e:\r\n        print(f"\\n\u2717 Exercise failed with error: {e}")\r\n        import traceback\r\n        traceback.print_exc()\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-create-sensor-integration-script",children:"Step 3: Create Sensor Integration Script"}),"\n",(0,i.jsxs)(n.p,{children:["Create a script to handle sensor data and ROS 2 integration (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/sensor_integration.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nSensor integration script for Isaac Sim exercise\r\n"""\r\n\r\nimport sys\r\nimport os\r\nimport numpy as np\r\n\r\n# Add Isaac Sim paths\r\nisaac_sim_path = os.environ.get(\'ISAAC_SIM_PATH\')\r\nif isaac_sim_path:\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'python\'))\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'kit\'))\r\n\r\n# Import Isaac Sim modules\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.prims import get_prim_at_path\r\n\r\n# Import sensor modules\r\nfrom omni.isaac.sensor import Camera, RotatingLidarPhysX\r\nfrom omni.isaac.core.sensors import Imu\r\n\r\n# Import ROS 2 bridge (if available)\r\ntry:\r\n    import rclpy\r\n    from sensor_msgs.msg import Image, LaserScan, Imu as ImuMsg\r\n    from geometry_msgs.msg import Twist\r\n    from std_msgs.msg import Header\r\n    ROS2_AVAILABLE = True\r\nexcept ImportError:\r\n    ROS2_AVAILABLE = False\r\n    print("ROS 2 not available, running in Isaac Sim only mode")\r\n\r\n\r\nclass IsaacSimSensorProcessor:\r\n    """Class to handle sensor data processing"""\r\n    \r\n    def __init__(self, robot_path="/World/ExerciseRobot"):\r\n        self.robot_path = robot_path\r\n        self.world = None\r\n        self.camera = None\r\n        self.lidar = None\r\n        self.imu = None\r\n        \r\n        # ROS 2 related\r\n        self.ros_node = None\r\n        self.ros_initialized = False\r\n        \r\n        # Sensor data storage\r\n        self.camera_data = None\r\n        self.lidar_data = None\r\n        self.imu_data = None\r\n        \r\n    def initialize_sensors(self):\r\n        """Initialize all sensors in the simulation"""\r\n        print("Initializing sensors...")\r\n        \r\n        # Initialize sensors if they exist\r\n        try:\r\n            # Initialize camera\r\n            camera_path = f"{self.robot_path}/FrontCamera"\r\n            camera_prim = get_prim_at_path(camera_path)\r\n            if camera_prim:\r\n                self.camera = Camera(prim_path=camera_path)\r\n                self.camera.initialize()\r\n                print("\u2713 Camera initialized")\r\n            else:\r\n                print("\u26a0 Camera not found in scene")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to initialize camera: {e}")\r\n        \r\n        try:\r\n            # Initialize LiDAR\r\n            lidar_path = f"{self.robot_path}/Lidar"\r\n            lidar_prim = get_prim_at_path(lidar_path)\r\n            if lidar_prim:\r\n                self.lidar = RotatingLidarPhysX(prim_path=lidar_path)\r\n                self.lidar.initialize()\r\n                print("\u2713 LiDAR initialized")\r\n            else:\r\n                print("\u26a0 LiDAR not found in scene")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to initialize LiDAR: {e}")\r\n        \r\n        try:\r\n            # Initialize IMU\r\n            imu_path = f"{self.robot_path}/Imu"\r\n            imu_prim = get_prim_at_path(imu_path)\r\n            if imu_prim:\r\n                self.imu = Imu(prim_path=imu_path)\r\n                self.imu.initialize()\r\n                print("\u2713 IMU initialized")\r\n            else:\r\n                print("\u26a0 IMU not found in scene")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to initialize IMU: {e}")\r\n    \r\n    def initialize_ros2(self):\r\n        """Initialize ROS 2 communication if available"""\r\n        if not ROS2_AVAILABLE:\r\n            print("\u26a0 ROS 2 not available, skipping initialization")\r\n            return False\r\n        \r\n        try:\r\n            rclpy.init()\r\n            self.ros_node = rclpy.create_node(\'isaac_sim_sensor_processor\')\r\n            \r\n            # Create publishers for sensor data\r\n            self.image_pub = self.ros_node.create_publisher(Image, \'/camera/image_raw\', 10)\r\n            self.laser_pub = self.ros_node.create_publisher(LaserScan, \'/scan\', 10)\r\n            self.imu_pub = self.ros_node.create_publisher(ImuMsg, \'/imu/data\', 10)\r\n            \r\n            # Create subscriber for robot control\r\n            self.cmd_vel_sub = self.ros_node.create_subscription(\r\n                Twist, \'/cmd_vel\', self.cmd_vel_callback, 10)\r\n            \r\n            print("\u2713 ROS 2 initialized")\r\n            self.ros_initialized = True\r\n            return True\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to initialize ROS 2: {e}")\r\n            return False\r\n    \r\n    def cmd_vel_callback(self, msg):\r\n        """Handle velocity commands from ROS 2"""\r\n        print(f"Received velocity command: linear={msg.linear.x}, angular={msg.angular.z}")\r\n        # In a real implementation, this would control the robot\r\n        # For now, we\'ll just print the command\r\n    \r\n    def capture_sensor_data(self):\r\n        """Capture and process data from all sensors"""\r\n        try:\r\n            # Capture camera data\r\n            if self.camera:\r\n                try:\r\n                    self.camera_data = self.camera.get_rgb()\r\n                    print(f"\u2713 Captured camera data: shape {self.camera_data.shape}")\r\n                    \r\n                    # Publish to ROS 2 if available\r\n                    if self.ros_initialized:\r\n                        self.publish_camera_data()\r\n                        \r\n                except Exception as e:\r\n                    print(f"\u2717 Failed to capture camera data: {e}")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 Camera capture error: {e}")\r\n        \r\n        try:\r\n            # Capture LiDAR data\r\n            if self.lidar:\r\n                try:\r\n                    self.lidar_data = self.lidar.get_linear_depth_data()\r\n                    print(f"\u2713 Captured LiDAR data: shape {self.lidar_data.shape}")\r\n                    \r\n                    # Publish to ROS 2 if available\r\n                    if self.ros_initialized:\r\n                        self.publish_lidar_data()\r\n                        \r\n                except Exception as e:\r\n                    print(f"\u2717 Failed to capture LiDAR data: {e}")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 LiDAR capture error: {e}")\r\n        \r\n        try:\r\n            # Capture IMU data\r\n            if self.imu:\r\n                try:\r\n                    self.imu_data = {\r\n                        \'linear_acceleration\': self.imu.get_linear_acceleration(),\r\n                        \'angular_velocity\': self.imu.get_angular_velocity()\r\n                    }\r\n                    print(f"\u2713 Captured IMU data: linear_acc={self.imu_data[\'linear_acceleration\']}")\r\n                    \r\n                    # Publish to ROS 2 if available\r\n                    if self.ros_initialized:\r\n                        self.publish_imu_data()\r\n                        \r\n                except Exception as e:\r\n                    print(f"\u2717 Failed to capture IMU data: {e}")\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 IMU capture error: {e}")\r\n    \r\n    def publish_camera_data(self):\r\n        """Publish camera data to ROS 2"""\r\n        if not (self.ros_initialized and self.camera_data is not None):\r\n            return\r\n        \r\n        try:\r\n            # Convert numpy array to ROS Image message\r\n            header = Header()\r\n            header.stamp = self.ros_node.get_clock().now().to_msg()\r\n            header.frame_id = "camera_frame"\r\n            \r\n            # Create Image message (simplified - in practice you\'d convert the data properly)\r\n            img_msg = Image()\r\n            img_msg.header = header\r\n            img_msg.height = self.camera_data.shape[0]\r\n            img_msg.width = self.camera_data.shape[1]\r\n            img_msg.encoding = "rgb8"  # TODO: Proper conversion needed\r\n            img_msg.is_bigendian = False\r\n            img_msg.step = self.camera_data.shape[1] * 3  # 3 channels (RGB)\r\n            # img_msg.data = self.camera_data.flatten().tobytes()  # TODO: Proper data conversion\r\n            \r\n            self.image_pub.publish(img_msg)\r\n            print("\u2713 Camera data published to ROS 2")\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to publish camera data: {e}")\r\n    \r\n    def publish_lidar_data(self):\r\n        """Publish LiDAR data to ROS 2"""\r\n        if not (self.ros_initialized and self.lidar_data is not None):\r\n            return\r\n        \r\n        try:\r\n            # Convert lidar data to LaserScan message\r\n            laser_msg = LaserScan()\r\n            laser_msg.header.stamp = self.ros_node.get_clock().now().to_msg()\r\n            laser_msg.header.frame_id = "lidar_frame"\r\n            \r\n            # Define scan parameters (these should match your LiDAR config)\r\n            laser_msg.angle_min = -np.pi  # Assuming 360\xb0 scan\r\n            laser_msg.angle_max = np.pi\r\n            laser_msg.angle_increment = 2 * np.pi / len(self.lidar_data) if len(self.lidar_data) > 0 else 0.01\r\n            laser_msg.time_increment = 0.0  # Time between measurements\r\n            laser_msg.scan_time = 0.1  # Time between scans\r\n            laser_msg.range_min = 0.1  # Minimum range\r\n            laser_msg.range_max = 10.0  # Maximum range\r\n            \r\n            # Convert distance data to ranges\r\n            laser_msg.ranges = self.lidar_data.tolist() if self.lidar_data is not None else []\r\n            laser_msg.intensities = []  # No intensity data for depth only\r\n            \r\n            self.laser_pub.publish(laser_msg)\r\n            print("\u2713 LiDAR data published to ROS 2")\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to publish LiDAR data: {e}")\r\n    \r\n    def publish_imu_data(self):\r\n        """Publish IMU data to ROS 2"""\r\n        if not (self.ros_initialized and self.imu_data is not None):\r\n            return\r\n        \r\n        try:\r\n            # Create IMU message\r\n            imu_msg = ImuMsg()\r\n            imu_msg.header.stamp = self.ros_node.get_clock().now().to_msg()\r\n            imu_msg.header.frame_id = "imu_frame"\r\n            \r\n            # Set linear acceleration\r\n            imu_msg.linear_acceleration.x = self.imu_data[\'linear_acceleration\'][0]\r\n            imu_msg.linear_acceleration.y = self.imu_data[\'linear_acceleration\'][1]\r\n            imu_msg.linear_acceleration.z = self.imu_data[\'linear_acceleration\'][2]\r\n            \r\n            # For angular velocity and orientation, we\'d need additional data\r\n            # Set to zero for now (in practice, you\'d integrate or use other sources)\r\n            imu_msg.angular_velocity.x = self.imu_data[\'angular_velocity\'][0]\r\n            imu_msg.angular_velocity.y = self.imu_data[\'angular_velocity\'][1]\r\n            imu_msg.angular_velocity.z = self.imu_data[\'angular_velocity\'][2]\r\n            \r\n            # Orientation unavailable from this IMU API\r\n            imu_msg.orientation.w = 1.0  # Default orientation\r\n            \r\n            self.imu_pub.publish(imu_msg)\r\n            print("\u2713 IMU data published to ROS 2")\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 Failed to publish IMU data: {e}")\r\n    \r\n    def run_sensor_loop(self, num_steps=200):\r\n        """Run the sensor processing loop"""\r\n        print(f"Starting sensor processing loop for {num_steps} steps...")\r\n        \r\n        # Initialize world if not done already\r\n        if not self.world:\r\n            self.world = World(stage_units_in_meters=1.0)\r\n            self.world.scene.add_default_ground_plane()\r\n            \r\n            # Add a simple robot if needed\r\n            assets_root_path = get_assets_root_path()\r\n            if assets_root_path:\r\n                try:\r\n                    self.world.scene.add(\r\n                        Robot(\r\n                            prim_path="/World/SensorRobot",\r\n                            name="sensor_robot",\r\n                            usd_path=assets_root_path + "/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\r\n                            position=[0, 0, 0.1],\r\n                            orientation=[0, 0, 0, 1]\r\n                        )\r\n                    )\r\n                except:\r\n                    print("Using basic robot for sensor testing")\r\n                    from omni.isaac.core.utils.prims import create_prim\r\n                    create_prim(\r\n                        prim_path="/World/SensorRobot",\r\n                        prim_type="Xform",\r\n                        position=[0, 0, 0.5]\r\n                    )\r\n            \r\n            self.world.reset()\r\n        \r\n        # Initialize sensors and ROS2\r\n        self.initialize_sensors()\r\n        self.initialize_ros2()\r\n        \r\n        # Main sensor loop\r\n        for i in range(num_steps):\r\n            # Step the simulation\r\n            self.world.step(render=True)\r\n            \r\n            # Capture sensor data periodically\r\n            if i % 10 == 0:  # Capture data every 10 steps\r\n                self.capture_sensor_data()\r\n                \r\n                # Spin ROS 2 to process callbacks\r\n                if self.ros_node:\r\n                    rclpy.spin_once(self.ros_node, timeout_sec=0.01)\r\n        \r\n        # Cleanup\r\n        if self.ros_node:\r\n            self.ros_node.destroy_node()\r\n            rclpy.shutdown()\r\n        \r\n        if self.world:\r\n            self.world.clear()\r\n        \r\n        print("\u2713 Sensor processing loop completed")\r\n\r\n\r\ndef main():\r\n    """Main function to run sensor integration exercise"""\r\n    print("="*60)\r\n    print("Isaac Sim Exercise: Sensor Integration")\r\n    print("="*60)\r\n    \r\n    # Create sensor processor\r\n    sensor_processor = IsaacSimSensorProcessor()\r\n    \r\n    try:\r\n        sensor_processor.run_sensor_loop(num_steps=200)\r\n        print("\\n\u2713 Sensor integration exercise completed successfully!")\r\n        \r\n    except Exception as e:\r\n        print(f"\\n\u2717 Sensor integration exercise failed: {e}")\r\n        import traceback\r\n        traceback.print_exc()\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"exercise-2-robot-navigation-in-isaac-sim",children:"Exercise 2: Robot Navigation in Isaac Sim"}),"\n",(0,i.jsx)(n.h3,{id:"objective-1",children:"Objective"}),"\n",(0,i.jsx)(n.p,{children:"Implement a basic navigation system in Isaac Sim using path planning and obstacle avoidance."}),"\n",(0,i.jsxs)(n.p,{children:["Create the navigation script (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/navigation_exercise.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nNavigation exercise script for Isaac Sim\r\n"""\r\n\r\nimport sys\r\nimport os\r\nimport numpy as np\r\nimport math\r\n\r\n# Add Isaac Sim paths\r\nisaac_sim_path = os.environ.get(\'ISAAC_SIM_PATH\')\r\nif isaac_sim_path:\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'python\'))\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'kit\'))\r\n\r\n# Import Isaac Sim modules\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.prims import create_prim\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\nfrom omni.isaac.core.utils.viewports import get_viewport_window\r\nfrom omni.isaac.core.materials import PreviewSurface\r\n\r\n# Import sensor modules\r\nfrom omni.isaac.sensor import RotatingLidarPhysX\r\n\r\n\r\nclass IsaacSimNavigationExercise:\r\n    """Class to handle navigation in Isaac Sim"""\r\n    \r\n    def __init__(self):\r\n        self.world = None\r\n        self.robot = None\r\n        self.lidar = None\r\n        self.robot_path = "/World/NavigationRobot"\r\n        self.target_position = np.array([3.0, 2.0, 0.0])\r\n        self.current_position = np.array([0.0, 0.0, 0.0])\r\n        self.current_orientation = 0.0  # Yaw angle in radians\r\n        \r\n        # Navigation parameters\r\n        self.linear_speed = 0.3  # m/s\r\n        self.angular_speed = 0.5  # rad/s\r\n        self.safe_distance = 0.8  # meters\r\n        self.arrival_threshold = 0.3  # meters\r\n        \r\n        # Path planning\r\n        self.path = []\r\n        self.path_index = 0\r\n    \r\n    def setup_world(self):\r\n        """Set up the navigation world with obstacles"""\r\n        print("Setting up navigation world...")\r\n        \r\n        # Create the world\r\n        self.world = World(stage_units_in_meters=1.0)\r\n        self.world.scene.add_default_ground_plane()\r\n        \r\n        # Add start and target positions\r\n        # Start position: (0, 0)\r\n        # Target position: (3, 2)\r\n        \r\n        # Add obstacles\r\n        create_prim(\r\n            prim_path="/World/Obstacle1",\r\n            prim_type="Cylinder",\r\n            position=[1.5, 1.0, 0.5],\r\n            scale=[0.5, 0.5, 1.0]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path="/World/Obstacle2",\r\n            prim_type="Cube",\r\n            position=[2.0, -1.0, 0.5],\r\n            scale=[0.7, 0.7, 1.0]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path="/World/Obstacle3",\r\n            prim_type="Cylinder",\r\n            position=[0.5, 2.0, 0.5],\r\n            scale=[0.4, 0.4, 1.0]\r\n        )\r\n        \r\n        # Add target marker\r\n        create_prim(\r\n            prim_path="/World/Target",\r\n            prim_type="Sphere",\r\n            position=[self.target_position[0], self.target_position[1], 0.5],\r\n            scale=[0.3, 0.3, 0.3]\r\n        )\r\n        \r\n        # Get robot assets and add to world\r\n        assets_root_path = get_assets_root_path()\r\n        if assets_root_path:\r\n            try:\r\n                self.robot = self.world.scene.add(\r\n                    Robot(\r\n                        prim_path=self.robot_path,\r\n                        name="navigation_robot",\r\n                        usd_path=assets_root_path + "/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\r\n                        position=[0, 0, 0.1],\r\n                        orientation=[0, 0, 0, 1]\r\n                    )\r\n                )\r\n            except:\r\n                print("Using basic robot for navigation exercise")\r\n                # Create a basic robot if assets unavailable\r\n                create_prim(\r\n                    prim_path=self.robot_path,\r\n                    prim_type="Xform",\r\n                    position=[0.0, 0.0, 0.5]\r\n                )\r\n        \r\n        # Add LiDAR to the robot\r\n        try:\r\n            self.lidar = RotatingLidarPhysX(\r\n                prim_path=f"{self.robot_path}/Lidar",\r\n                translation=np.array([0.05, 0, 0.2]),\r\n                config="Example_Rotary",\r\n                depth_range=10.0,\r\n                horizontal_resolution=0.25,\r\n                vertical_resolution=0.5,\r\n                horizontal_fov=360,\r\n                vertical_fov=30,\r\n                rotation_frequency=10,\r\n                samples_per_scan=1440\r\n            )\r\n            self.lidar.initialize()\r\n        except Exception as e:\r\n            print(f"LiDAR setup failed: {e}")\r\n        \r\n        # Reset the world to initialize all objects\r\n        self.world.reset()\r\n        \r\n        print("\u2713 Navigation world setup complete")\r\n    \r\n    def get_robot_state(self):\r\n        """Get current robot state (position and orientation)"""\r\n        if self.robot:\r\n            pos, quat = self.robot.get_world_pose()\r\n            self.current_position = np.array([pos[0], pos[1], pos[2]])\r\n            \r\n            # Convert quaternion to yaw (simplified for 2D navigation)\r\n            # For a quaternion [x, y, z, w], yaw = atan2(2*(w*z + x*y), w^2 + x^2 - y^2 - z^2)\r\n            w, x, y, z = quat\r\n            self.current_orientation = math.atan2(2*(w*z + x*y), w*w + x*x - y*y - z*z)\r\n        \r\n        return self.current_position, self.current_orientation\r\n    \r\n    def get_lidar_data(self):\r\n        """Get LiDAR data to detect obstacles"""\r\n        if self.lidar:\r\n            try:\r\n                return self.lidar.get_linear_depth_data()\r\n            except:\r\n                # Return empty data if LiDAR is not available\r\n                return np.ones(360) * 10.0\r\n        else:\r\n            # Return empty data if no LiDAR\r\n            return np.ones(360) * 10.0\r\n    \r\n    def check_obstacles_ahead(self, lidar_data):\r\n        """Check for obstacles in front of the robot"""\r\n        # Check the front 30 degrees of the LiDAR data (15 points)\r\n        front_start = len(lidar_data) // 2 - 15\r\n        front_end = len(lidar_data) // 2 + 15\r\n        \r\n        if front_start < 0:\r\n            front_start = 0\r\n        if front_end >= len(lidar_data):\r\n            front_end = len(lidar_data) - 1\r\n        \r\n        # Check if any distance is less than safe distance\r\n        for i in range(front_start, front_end):\r\n            if lidar_data[i] < self.safe_distance and not np.isnan(lidar_data[i]):\r\n                return True\r\n        \r\n        return False\r\n    \r\n    def calculate_control_command(self):\r\n        """Calculate control command to navigate to target"""\r\n        # Get current state\r\n        pos, orientation = self.get_robot_state()\r\n        \r\n        # Calculate direction to target\r\n        target_delta = self.target_position - pos\r\n        target_distance = np.linalg.norm(target_delta[:2])  # Only x,y plane\r\n        \r\n        # Check if we\'ve reached the target\r\n        if target_distance < self.arrival_threshold:\r\n            return 0.0, 0.0  # Stop moving\r\n        \r\n        # Calculate target angle\r\n        target_angle = np.arctan2(target_delta[1], target_delta[0])\r\n        \r\n        # Calculate angle difference\r\n        angle_diff = target_angle - orientation\r\n        # Normalize angle to [-\u03c0, \u03c0]\r\n        while angle_diff > math.pi:\r\n            angle_diff -= 2 * math.pi\r\n        while angle_diff < -math.pi:\r\n            angle_diff += 2 * math.pi\r\n        \r\n        # Get LiDAR data to check for obstacles\r\n        lidar_data = self.get_lidar_data()\r\n        obstacle_ahead = self.check_obstacles_ahead(lidar_data)\r\n        \r\n        # Navigation logic\r\n        if obstacle_ahead:\r\n            # If obstacle ahead, turn away\r\n            return 0.0, self.angular_speed  # Rotate to avoid obstacle\r\n        elif abs(angle_diff) > 0.2:  # If not aligned with target\r\n            # Rotate toward target\r\n            angular_cmd = self.angular_speed if angle_diff > 0 else -self.angular_speed\r\n            return 0.0, angular_cmd\r\n        else:\r\n            # Move toward target\r\n            return self.linear_speed, 0.0\r\n    \r\n    def execute_navigation(self, max_steps=2000):\r\n        """Execute the navigation task"""\r\n        print("Starting navigation task...")\r\n        print(f"Target position: [{self.target_position[0]:.2f}, {self.target_position[1]:.2f}]")\r\n        \r\n        reached_target = False\r\n        \r\n        for step in range(max_steps):\r\n            # Step the simulation\r\n            self.world.step(render=True)\r\n            \r\n            # Calculate control commands every few steps for efficiency\r\n            if step % 5 == 0:\r\n                linear_vel, angular_vel = self.calculate_control_command()\r\n                \r\n                # Apply control (in a real implementation, you\'d control the robot\'s actuators)\r\n                # For this exercise, we\'ll just print the commands\r\n                print(f"Step {step}: v={linear_vel:.2f}, \u03c9={angular_vel:.2f}")\r\n                \r\n                # Check if we\'ve reached the target\r\n                pos, _ = self.get_robot_state()\r\n                distance_to_target = np.linalg.norm(self.target_position[:2] - pos[:2])\r\n                \r\n                if distance_to_target < self.arrival_threshold:\r\n                    print(f"\u2713 Reached target! Final distance: {distance_to_target:.2f}m")\r\n                    reached_target = True\r\n                    break\r\n            \r\n            # Print status periodically\r\n            if step % 100 == 0:\r\n                pos, _ = self.get_robot_state()\r\n                distance_to_target = np.linalg.norm(self.target_position[:2] - pos[:2])\r\n                print(f"Step {step}: Distance to target: {distance_to_target:.2f}m")\r\n        \r\n        if not reached_target:\r\n            pos, _ = self.get_robot_state()\r\n            distance_to_target = np.linalg.norm(self.target_position[:2] - pos[:2])\r\n            print(f"\u26a0 Navigation ended without reaching target. Final distance: {distance_to_target:.2f}m")\r\n        \r\n        print("\u2713 Navigation task completed")\r\n    \r\n    def run_exercise(self):\r\n        """Run the complete navigation exercise"""\r\n        print("="*60)\r\n        print("Isaac Sim Exercise: Robot Navigation")\r\n        print("="*60)\r\n        \r\n        try:\r\n            self.setup_world()\r\n            self.execute_navigation(max_steps=2000)\r\n            \r\n            # Cleanup\r\n            self.world.clear()\r\n            \r\n            print("\\n\u2713 Navigation exercise completed!")\r\n            \r\n        except Exception as e:\r\n            print(f"\\n\u2717 Navigation exercise failed: {e}")\r\n            import traceback\r\n            traceback.print_exc()\r\n\r\n\r\ndef main():\r\n    """Main function to run navigation exercise"""\r\n    nav_exercise = IsaacSimNavigationExercise()\r\n    nav_exercise.run_exercise()\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"exercise-3-advanced-sensor-processing",children:"Exercise 3: Advanced Sensor Processing"}),"\n",(0,i.jsx)(n.h3,{id:"objective-2",children:"Objective"}),"\n",(0,i.jsx)(n.p,{children:"Implement advanced sensor processing including SLAM-like capabilities using Isaac Sim sensors."}),"\n",(0,i.jsxs)(n.p,{children:["Create the advanced sensor script (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/advanced_sensor_exercise.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nAdvanced sensor processing exercise for Isaac Sim\r\n"""\r\n\r\nimport sys\r\nimport os\r\nimport numpy as np\r\nimport math\r\nfrom collections import deque\r\n\r\n# Add Isaac Sim paths\r\nisaac_sim_path = os.environ.get(\'ISAAC_SIM_PATH\')\r\nif isaac_sim_path:\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'python\'))\r\n    sys.path.insert(0, os.path.join(isaac_sim_path, \'kit\'))\r\n\r\n# Import Isaac Sim modules\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nfrom omni.isaac.core.utils.prims import create_prim\r\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\r\n\r\n# Import sensor modules\r\nfrom omni.isaac.sensor import RotatingLidarPhysX, Camera\r\nfrom omni.isaac.core.sensors import Imu\r\n\r\n\r\nclass AdvancedSensorProcessor:\r\n    """Class to handle advanced sensor processing"""\r\n    \r\n    def __init__(self):\r\n        self.world = None\r\n        self.robot = None\r\n        self.lidar = None\r\n        self.camera = None\r\n        self.imu = None\r\n        \r\n        # Sensor data storage\r\n        self.lidar_data = None\r\n        self.camera_data = None\r\n        self.imu_data = None\r\n        \r\n        # Robot state tracking\r\n        self.position_history = deque(maxlen=100)\r\n        self.orientation_history = deque(maxlen=100)\r\n        \r\n        # Mapping and localization\r\n        self.occupancy_grid = np.zeros((100, 100))  # Simple 100x100 grid\r\n        self.grid_resolution = 0.1  # 10cm per cell\r\n        self.grid_offset = np.array([50, 50])  # Center of grid at (0,0)\r\n        \r\n        # Feature detection\r\n        self.features = []  # Detected features in the environment\r\n    \r\n    def setup_environment(self):\r\n        """Set up the environment for advanced sensor processing"""\r\n        print("Setting up advanced sensor processing environment...")\r\n        \r\n        # Create the world\r\n        self.world = World(stage_units_in_meters=1.0)\r\n        self.world.scene.add_default_ground_plane()\r\n        \r\n        # Add various objects to create a rich environment for sensing\r\n        # Add multiple obstacles of different shapes\r\n        create_prim(\r\n            prim_path="/World/Obstacle_Sphere",\r\n            prim_type="Sphere",\r\n            position=[2.0, 1.0, 0.5],\r\n            scale=[0.3, 0.3, 0.3]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path="/World/Obstacle_Box",\r\n            prim_type="Cube",\r\n            position=[-1.5, 2.0, 0.5],\r\n            scale=[0.5, 0.8, 1.0]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path="/World/Obstacle_Cylinder",\r\n            prim_type="Cylinder",\r\n            position=[1.0, -2.0, 0.7],\r\n            scale=[0.4, 0.4, 1.4]\r\n        )\r\n        \r\n        # Add some walls\r\n        create_prim(\r\n            prim_path="/World/Wall_Vertical",\r\n            prim_type="Cuboid",\r\n            position=[3.0, 0, 1.0],\r\n            scale=[0.1, 4.0, 2.0]\r\n        )\r\n        \r\n        create_prim(\r\n            prim_path="/World/Wall_Horizontal",\r\n            prim_type="Cuboid",\r\n            position=[0, 3.0, 1.0],\r\n            scale=[4.0, 0.1, 2.0]\r\n        )\r\n        \r\n        # Add robot\r\n        assets_root_path = get_assets_root_path()\r\n        if assets_root_path:\r\n            try:\r\n                self.robot = self.world.scene.add(\r\n                    Robot(\r\n                        prim_path="/World/AdvancedSensorRobot",\r\n                        name="advanced_sensor_robot",\r\n                        usd_path=assets_root_path + "/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\r\n                        position=[0, 0, 0.1],\r\n                        orientation=[0, 0, 0, 1]\r\n                    )\r\n                )\r\n            except:\r\n                # Fallback: create basic robot\r\n                create_prim(\r\n                    prim_path="/World/AdvancedSensorRobot",\r\n                    prim_type="Xform",\r\n                    position=[0.0, 0.0, 0.5]\r\n                )\r\n        \r\n        # Add sensors to robot\r\n        try:\r\n            # Add LiDAR\r\n            self.lidar = RotatingLidarPhysX(\r\n                prim_path="/World/AdvancedSensorRobot/Lidar",\r\n                translation=np.array([0.05, 0, 0.2]),\r\n                config="Example_Rotary",\r\n                depth_range=10.0,\r\n                horizontal_resolution=0.25,\r\n                vertical_resolution=0.5,\r\n                horizontal_fov=360,\r\n                vertical_fov=30,\r\n                rotation_frequency=10,\r\n                samples_per_scan=1440\r\n            )\r\n            self.lidar.initialize()\r\n        except:\r\n            print("LiDAR initialization failed")\r\n        \r\n        try:\r\n            # Add camera\r\n            self.camera = Camera(\r\n                prim_path="/World/AdvancedSensorRobot/Camera",\r\n                position=np.array([0.1, 0, 0.1]),\r\n                frequency=30,\r\n                resolution=(640, 480)\r\n            )\r\n            self.camera.initialize()\r\n        except:\r\n            print("Camera initialization failed")\r\n        \r\n        try:\r\n            # Add IMU\r\n            self.imu = Imu(\r\n                prim_path="/World/AdvancedSensorRobot/Imu",\r\n                position=np.array([0.0, 0.0, 0.1]),\r\n                orientation=np.array([0, 0, 0, 1])\r\n            )\r\n            self.imu.initialize()\r\n        except:\r\n            print("IMU initialization failed")\r\n        \r\n        # Reset the world\r\n        self.world.reset()\r\n        print("\u2713 Advanced sensor processing environment setup complete")\r\n    \r\n    def get_robot_pose(self):\r\n        """Get robot\'s current position and orientation"""\r\n        if self.robot:\r\n            pos, quat = self.robot.get_world_pose()\r\n            \r\n            # Convert quaternion to yaw angle\r\n            w, x, y, z = quat\r\n            yaw = math.atan2(2*(w*z + x*y), w*w + x*x - y*y - z*z)\r\n            \r\n            return np.array([pos[0], pos[1], pos[2]]), yaw\r\n        \r\n        return np.array([0.0, 0.0, 0.0]), 0.0\r\n    \r\n    def process_lidar_data(self):\r\n        """Process LiDAR data to detect obstacles and map environment"""\r\n        if not self.lidar:\r\n            return\r\n        \r\n        try:\r\n            lidar_data = self.lidar.get_linear_depth_data()\r\n            \r\n            if lidar_data is not None and len(lidar_data) > 0:\r\n                # Get robot\'s current pose\r\n                robot_pos, robot_yaw = self.get_robot_pose()\r\n                \r\n                # Convert polar coordinates to Cartesian for mapping\r\n                angles = np.linspace(-np.pi, np.pi, len(lidar_data))\r\n                \r\n                # Filter out invalid measurements\r\n                valid_indices = np.where((lidar_data > 0.1) & (lidar_data < 10.0))\r\n                valid_ranges = lidar_data[valid_indices]\r\n                valid_angles = angles[valid_indices]\r\n                \r\n                # Convert to global coordinates\r\n                local_x = valid_ranges * np.cos(valid_angles)\r\n                local_y = valid_ranges * np.sin(valid_angles)\r\n                \r\n                # Transform to global frame\r\n                cos_yaw = np.cos(robot_yaw)\r\n                sin_yaw = np.sin(robot_yaw)\r\n                \r\n                global_x = local_x * cos_yaw - local_y * sin_yaw + robot_pos[0]\r\n                global_y = local_x * sin_yaw + local_y * cos_yaw + robot_pos[1]\r\n                \r\n                # Update occupancy grid\r\n                for x, y in zip(global_x, global_y):\r\n                    # Convert world coordinates to grid coordinates\r\n                    grid_x = int((x / self.grid_resolution) + self.grid_offset[0])\r\n                    grid_y = int((y / self.grid_resolution) + self.grid_offset[1])\r\n                    \r\n                    # Check bounds\r\n                    if 0 <= grid_x < self.occupancy_grid.shape[0] and 0 <= grid_y < self.occupancy_grid.shape[1]:\r\n                        # Mark as occupied (set to 1)\r\n                        self.occupancy_grid[grid_x, grid_y] = 1\r\n                \r\n                # Also mark robot\'s current position as free\r\n                robot_grid_x = int((robot_pos[0] / self.grid_resolution) + self.grid_offset[0])\r\n                robot_grid_y = int((robot_pos[1] / self.grid_resolution) + self.grid_offset[1])\r\n                \r\n                if 0 <= robot_grid_x < self.occupancy_grid.shape[0] and 0 <= robot_grid_y < self.occupancy_grid.shape[1]:\r\n                    # Mark robot position as free\r\n                    self.occupancy_grid[robot_grid_x, robot_grid_y] = 0.5  # Free space\r\n                \r\n                print(f"\u2713 Processed LiDAR data: {len(valid_ranges)} valid measurements")\r\n                return True\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 LiDAR processing error: {e}")\r\n        \r\n        return False\r\n    \r\n    def process_camera_data(self):\r\n        """Process camera data to detect features"""\r\n        if not self.camera:\r\n            return\r\n        \r\n        try:\r\n            camera_data = self.camera.get_rgb()\r\n            \r\n            if camera_data is not None and camera_data.size > 0:\r\n                # In a real implementation, you would perform computer vision processing\r\n                # such as feature detection, object recognition, etc.\r\n                \r\n                print(f"\u2713 Processed camera data: shape {camera_data.shape}")\r\n                \r\n                # For this exercise, we\'ll just record that we have image data\r\n                self.camera_data = camera_data\r\n                \r\n                # Example feature detection (simplified)\r\n                height, width = camera_data.shape[:2]\r\n                \r\n                # Detect corners using a simple method (simplified)\r\n                corners = []\r\n                \r\n                # In a real implementation, you would use OpenCV or other CV library\r\n                # For now, just simulate detecting some features\r\n                corners.append((width//4, height//4))    # Top left\r\n                corners.append((3*width//4, height//4))  # Top right\r\n                corners.append((width//4, 3*height//4)) # Bottom left\r\n                corners.append((3*width//4, 3*height//4)) # Bottom right\r\n                \r\n                print(f"\u2713 Detected {len(corners)} features in camera view")\r\n                \r\n                return True\r\n        \r\n        except Exception as e:\r\n            print(f"\u2717 Camera processing error: {e}")\r\n        \r\n        return False\r\n    \r\n    def process_imu_data(self):\r\n        """Process IMU data for state estimation"""\r\n        if not self.imu:\r\n            return\r\n        \r\n        try:\r\n            linear_acc = self.imu.get_linear_acceleration()\r\n            angular_vel = self.imu.get_angular_velocity()\r\n            \r\n            # Store data\r\n            self.imu_data = {\r\n                \'linear_acceleration\': linear_acc,\r\n                \'angular_velocity\': angular_vel\r\n            }\r\n            \r\n            print(f"\u2713 Processed IMU data: acc=({linear_acc[0]:.3f}, {linear_acc[1]:.3f}, {linear_acc[2]:.3f})")\r\n            return True\r\n            \r\n        except Exception as e:\r\n            print(f"\u2717 IMU processing error: {e}")\r\n        \r\n        return False\r\n    \r\n    def create_occupancy_map(self):\r\n        """Create and visualize occupancy map from sensor data"""\r\n        print(f"Creating occupancy map from sensor data...")\r\n        \r\n        # In a real implementation, you would create a more sophisticated map\r\n        # For this exercise, we\'ll just print statistics about the grid\r\n        \r\n        occupied_cells = np.sum(self.occupancy_grid == 1)\r\n        free_cells = np.sum(self.occupancy_grid == 0.5)\r\n        unknown_cells = np.sum(self.occupancy_grid == 0)\r\n        \r\n        total_cells = self.occupancy_grid.size\r\n        \r\n        print(f"Occupancy map statistics:")\r\n        print(f"  Total cells: {total_cells}")\r\n        print(f"  Occupied: {occupied_cells} ({occupied_cells/total_cells*100:.1f}%)")\r\n        print(f"  Free: {free_cells} ({free_cells/total_cells*100:.1f}%)")\r\n        print(f"  Unknown: {unknown_cells} ({unknown_cells/total_cells*100:.1f}%)")\r\n        \r\n        # In a real implementation, you would save this as an image or use it for navigation\r\n        return self.occupancy_grid\r\n    \r\n    def estimate_robot_motion(self):\r\n        """Estimate robot motion using sensor fusion"""\r\n        print("Estimating robot motion...")\r\n        \r\n        # Get current pose\r\n        current_pos, current_yaw = self.get_robot_pose()\r\n        \r\n        # Store in history\r\n        self.position_history.append(current_pos.copy())\r\n        self.orientation_history.append(current_yaw)\r\n        \r\n        # Estimate velocity if we have enough history\r\n        if len(self.position_history) >= 2:\r\n            # Calculate displacement\r\n            prev_pos = self.position_history[-2]\r\n            displacement = current_pos - prev_pos\r\n            \r\n            # Calculate velocity (assuming fixed time step of 0.01s)\r\n            velocity = displacement / 0.01  # This is approximate\r\n            \r\n            print(f"Estimated velocity: ({velocity[0]:.3f}, {velocity[1]:.3f}, {velocity[2]:.3f}) m/s")\r\n        \r\n        return current_pos, current_yaw\r\n    \r\n    def run_sensor_processing_loop(self, num_steps=1000):\r\n        """Run the advanced sensor processing loop"""\r\n        print("Starting advanced sensor processing loop...")\r\n        \r\n        for step in range(num_steps):\r\n            # Step the simulation\r\n            self.world.step(render=True)\r\n            \r\n            # Process sensors every few steps\r\n            if step % 10 == 0:\r\n                print(f"\\nProcessing step {step}...")\r\n                \r\n                # Process all sensors\r\n                lidar_ok = self.process_lidar_data()\r\n                camera_ok = self.process_camera_data()\r\n                imu_ok = self.process_imu_data()\r\n                \r\n                # Estimate motion\r\n                pos, yaw = self.estimate_robot_motion()\r\n                print(f"Robot pose: pos=({pos[0]:.2f}, {pos[1]:.2f}), yaw={yaw:.3f}")\r\n                \r\n                # Print processing status\r\n                status = "\u2713" if (lidar_ok or camera_ok or imu_ok) else "\u2717"\r\n                print(f"{status} Sensor processing completed")\r\n            \r\n            # Print occupancy map statistics periodically\r\n            if step % 100 == 0 and step > 0:\r\n                print(f"\\nStep {step} - Map Update:")\r\n                self.create_occupancy_map()\r\n        \r\n        print("\u2713 Advanced sensor processing loop completed")\r\n    \r\n    def run_exercise(self):\r\n        """Run the complete advanced sensor processing exercise"""\r\n        print("="*60)\r\n        print("Isaac Sim Exercise: Advanced Sensor Processing")\r\n        print("="*60)\r\n        \r\n        try:\r\n            self.setup_environment()\r\n            self.run_sensor_processing_loop(num_steps=1000)\r\n            \r\n            # Final map\r\n            print(f"\\nFinal occupancy map:")\r\n            occupancy_map = self.create_occupancy_map()\r\n            \r\n            # Cleanup\r\n            self.world.clear()\r\n            \r\n            print("\\n\u2713 Advanced sensor processing exercise completed!")\r\n            \r\n        except Exception as e:\r\n            print(f"\\n\u2717 Advanced sensor processing exercise failed: {e}")\r\n            import traceback\r\n            traceback.print_exc()\r\n\r\n\r\ndef main():\r\n    """Main function to run advanced sensor processing exercise"""\r\n    sensor_processor = AdvancedSensorProcessor()\r\n    sensor_processor.run_exercise()\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"exercise-4-isaac-sim-extension-development",children:"Exercise 4: Isaac Sim Extension Development"}),"\n",(0,i.jsx)(n.h3,{id:"objective-3",children:"Objective"}),"\n",(0,i.jsx)(n.p,{children:"Create a custom Isaac Sim extension for robotics applications."}),"\n",(0,i.jsxs)(n.p,{children:["Create the extension script (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/custom_extension_exercise.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example extension structure (this would typically be placed in the extensions folder)\r\n# For this exercise, we\'ll show how to structure and develop an extension\r\n\r\n"""\r\nCustom Isaac Sim Extension for Robotics\r\n\r\nThis example shows how to create a custom extension that adds robotics-specific\r\nfunctionality to Isaac Sim, such as a custom UI panel for robot control or\r\nan automated testing framework.\r\n"""\r\n\r\nimport omni.ext\r\nimport omni.ui as ui\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\r\nimport carb\r\n\r\n# The extension class\r\nclass RoboticsExtension(omni.ext.IExt):\r\n    """Custom Robotics Extension for Isaac Sim"""\r\n    \r\n    def on_startup(self, ext_id):\r\n        """Called when the extension is started"""\r\n        print(f"[robotics.extension] Starting extension: {ext_id}")\r\n        \r\n        # Create a UI window for the extension\r\n        self._window = ui.Window("Robotics Control", width=300, height=400)\r\n        \r\n        with self._window.frame:\r\n            with ui.VStack():\r\n                ui.Label("Robotics Extension Panel")\r\n                \r\n                # Add UI elements for robot control\r\n                self._robot_control_frame = ui.CollapsableFrame("Robot Control")\r\n                with self._robot_control_frame:\r\n                    with ui.VStack():\r\n                        # Add buttons for controlling a robot\r\n                        ui.Button("Move Forward", clicked_fn=self._move_forward)\r\n                        ui.Button("Move Backward", clicked_fn=self._move_backward)\r\n                        ui.Button("Turn Left", clicked_fn=self._turn_left)\r\n                        ui.Button("Turn Right", clicked_fn=self._turn_right)\r\n                        ui.Button("Stop", clicked_fn=self._stop_robot)\r\n                \r\n                # Add UI elements for sensor visualization\r\n                self._sensor_frame = ui.CollapsableFrame("Sensor Visualization")\r\n                with self._sensor_frame:\r\n                    with ui.VStack():\r\n                        ui.Button("Visualize LiDAR", clicked_fn=self._visualize_lidar)\r\n                        ui.Button("Show Camera Feed", clicked_fn=self._show_camera)\r\n        \r\n        # Initialize Isaac Sim components\r\n        self._world = World(stage_units_in_meters=1.0)\r\n        self._robot = None\r\n        \r\n        print("[robotics.extension] Extension started successfully")\r\n    \r\n    def on_shutdown(self):\r\n        """Called when the extension is shut down"""\r\n        print("[robotics.extension] Shutting down extension")\r\n        \r\n        # Clean up UI\r\n        if self._window:\r\n            self._window.destroy()\r\n        \r\n        # Clean up Isaac Sim components\r\n        if self._world:\r\n            self._world.cleanup()\r\n    \r\n    def _move_forward(self):\r\n        """Move robot forward"""\r\n        print("[robotics.extension] Move Forward command")\r\n        # In real implementation, this would control the robot\r\n        \r\n    def _move_backward(self):\r\n        """Move robot backward"""\r\n        print("[robotics.extension] Move Backward command")\r\n        \r\n    def _turn_left(self):\r\n        """Turn robot left"""\r\n        print("[robotics.extension] Turn Left command")\r\n        \r\n    def _turn_right(self):\r\n        """Turn robot right"""\r\n        print("[robotics.extension] Turn Right command")\r\n        \r\n    def _stop_robot(self):\r\n        """Stop robot motion"""\r\n        print("[robotics.extension] Stop command")\r\n    \r\n    def _visualize_lidar(self):\r\n        """Visualize LiDAR data"""\r\n        print("[robotics.extension] Visualize LiDAR command")\r\n    \r\n    def _show_camera(self):\r\n        """Show camera feed"""\r\n        print("[robotics.extension] Show Camera Feed command")\r\n\r\n\r\n# Additional utility functions for the extension\r\nclass RobotController:\r\n    """Utility class for robot control"""\r\n    \r\n    def __init__(self, world):\r\n        self._world = world\r\n        self._current_robot = None\r\n    \r\n    def add_robot(self, robot_usd_path, position=[0, 0, 0]):\r\n        """Add a robot to the simulation"""\r\n        try:\r\n            robot = self._world.scene.add(\r\n                Robot(\r\n                    prim_path="/World/CustomRobot",\r\n                    name="custom_robot",\r\n                    usd_path=robot_usd_path,\r\n                    position=position\r\n                )\r\n            )\r\n            self._current_robot = robot\r\n            return robot\r\n        except Exception as e:\r\n            carb.log_error(f"Failed to add robot: {e}")\r\n            return None\r\n    \r\n    def control_robot(self, linear_vel, angular_vel):\r\n        """Control the robot using differential drive"""\r\n        if self._current_robot:\r\n            # In a real implementation, this would set the robot\'s wheel velocities\r\n            # For now, we\'ll just log the command\r\n            print(f"Robot control command: linear={linear_vel}, angular={angular_vel}")\r\n\r\n\r\ndef create_extension():\r\n    """Helper function to create the extension"""\r\n    return RoboticsExtension()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"exercise-5-running-the-exercises",children:"Exercise 5: Running the Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"running-instructions",children:"Running Instructions"}),"\n",(0,i.jsxs)(n.p,{children:["Create a script to run all exercises (",(0,i.jsx)(n.code,{children:"~/isaac_sim_exercises/scripts/run_all_exercises.py"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nScript to run all Isaac Sim exercises\r\n"""\r\n\r\nimport subprocess\r\nimport sys\r\nimport os\r\n\r\ndef run_exercise(script_path, description):\r\n    """Run a single exercise"""\r\n    print(f"\\n{\'=\'*60}")\r\n    print(f"Running: {description}")\r\n    print(f"Script: {script_path}")\r\n    print(f"{\'=\'*60}")\r\n    \r\n    try:\r\n        result = subprocess.run([sys.executable, script_path], \r\n                              capture_output=True, text=True, timeout=120)\r\n        \r\n        if result.returncode == 0:\r\n            print("\u2713 Exercise completed successfully")\r\n            if result.stdout:\r\n                print(f"Output:\\n{result.stdout[-1000:]}")  # Last 1000 chars\r\n        else:\r\n            print(f"\u2717 Exercise failed with return code: {result.returncode}")\r\n            if result.stderr:\r\n                print(f"Error:\\n{result.stderr}")\r\n    \r\n    except subprocess.TimeoutExpired:\r\n        print("\u2717 Exercise timed out (120 seconds)")\r\n    except Exception as e:\r\n        print(f"\u2717 Failed to run exercise: {e}")\r\n\r\ndef main():\r\n    """Run all exercises"""\r\n    print("Isaac Sim Practical Exercises")\r\n    print("="*60)\r\n    \r\n    exercises_dir = os.path.dirname(os.path.abspath(__file__))\r\n    \r\n    exercises = [\r\n        ("setup_robot.py", "Exercise 1: Complete Robot Setup"),\r\n        ("sensor_integration.py", "Exercise 2: Sensor Integration"), \r\n        ("navigation_exercise.py", "Exercise 3: Robot Navigation"),\r\n        ("advanced_sensor_exercise.py", "Exercise 4: Advanced Sensor Processing")\r\n    ]\r\n    \r\n    for script, description in exercises:\r\n        script_path = os.path.join(exercises_dir, script)\r\n        if os.path.exists(script_path):\r\n            run_exercise(script_path, description)\r\n        else:\r\n            print(f"\\n\u26a0 Script not found: {script_path}")\r\n    \r\n    print(f"\\n{\'=\'*60}")\r\n    print("All exercises completed!")\r\n    print("="*60)\r\n\r\nif __name__ == "__main__":\r\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"This practical exercise module covered:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complete robot simulation"}),": Creating a robot with sensors in Isaac Sim"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor integration"}),": Working with cameras, LiDAR, and IMU sensors"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation"}),": Implementing path planning and obstacle avoidance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Advanced sensor processing"}),": Creating occupancy maps and state estimation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Extension development"}),": Creating custom Isaac Sim extensions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 integration"}),": Connecting Isaac Sim to ROS 2 systems"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"These exercises provide hands-on experience with Isaac Sim's robotics capabilities, from basic setup to advanced sensor processing. The exercises demonstrate:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"How to create complex simulation environments"}),"\n",(0,i.jsx)(n.li,{children:"How to integrate various sensors and process their data"}),"\n",(0,i.jsx)(n.li,{children:"How to implement navigation and control algorithms"}),"\n",(0,i.jsx)(n.li,{children:"How to develop custom extensions for specialized robotics applications"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The skills learned in these exercises form the foundation for using Isaac Sim for advanced robotics research and development, particularly in areas like autonomous navigation, sensor fusion, and AI training for robotics."}),"\n",(0,i.jsx)(n.p,{children:"This completes the submodules for Week 1 of Module 3 on NVIDIA Isaac Sim."})]})}function d(r={}){const{wrapper:n}={...(0,a.R)(),...r.components};return n?(0,i.jsx)(n,{...r,children:(0,i.jsx)(p,{...r})}):p(r)}},8453:(r,n,e)=>{e.d(n,{R:()=>s,x:()=>o});var t=e(6540);const i={},a=t.createContext(i);function s(r){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof r?r(n):{...n,...r}},[n,r])}function o(r){let n;return n=r.disableParentContext?"function"==typeof r.components?r.components(i):r.components||i:s(r.components),t.createElement(a.Provider,{value:n},r.children)}}}]);