"use strict";(globalThis.webpackChunkphysical_ai_platform_frontend=globalThis.webpackChunkphysical_ai_platform_frontend||[]).push([[3713],{6097:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4/week-3-vla-integration/3-1-vla-integration-with-robotics","title":"itt \u06c1 3: vla an \u0636 \u0645\u0645\u0627\u0645","description":"\u062c a \u062c","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/module-4/week-3-vla-integration/3-1-vla-integration-with-robotics.md","sourceDirName":"module-4/week-3-vla-integration","slug":"/module-4/week-3-vla-integration/3-1-vla-integration-with-robotics","permalink":"/ur/docs/module-4/week-3-vla-integration/3-1-vla-integration-with-robotics","draft":false,"unlisted":false,"editUrl":"https://github.com/noor-ana/physical-ai-platform/tree/main/docs/module-4/week-3-vla-integration/3-1-vla-integration-with-robotics.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"difficulty":"advanced"},"sidebar":"tutorialSidebar","previous":{"title":"\u0686\u0679 2: VLA \u0628\u0646 \u06cc Adatatatat","permalink":"/ur/docs/module-4/week-2-vla-fundamentals/2-1-introduction-to-vla-models"},"next":{"title":"\u062f\u0679 4: \u0627\u0639\u0644\u06cc \u062f\u0631\u06cc\u06cc\u062c\u06d2 \u06a9\u06cc vla a \u06cc\u067e la \u06cc \u06a9\u06cc\u0634 n \u0632","permalink":"/ur/docs/module-4/week-4-advanced-vla-applications/4-1-advanced-vla-applications"}}');var t=r(4848),s=r(8453);const l={sidebar_position:2,difficulty:"advanced"},i="itt \u06c1 3: vla an \u0636 \u0645\u0645\u0627\u0645",o={},c=[{value:"\u062c a \u062c",id:"\u062c-a-\u062c",level:2},{value:"ss \u06cc\u06a9\u06be n \u06d2 \u06a9\u06d2 maua \u0635 d",id:"ss-\u06cc\u06a9\u06be-n-\u06d2-\u06a9\u06d2-maua-\u0635-d",level:2},{value:"vla maa \u0688 l \u06a9\u06cc taia \u06cc nat \u06cc",id:"vla-maa-\u0688-l-\u06a9\u06cc-taia-\u06cc-nat-\u06cc",level:2},{value:"maa \u0688 l \u0622\u067e\u0679\u06cc maa \u0626\u0632\u06cc\u0634 n \u06a9\u06d2 l \u06cc\u06d2 rewbwaus",id:"maa-\u0688-l-\u0622\u067e\u0679\u06cc-maa-\u0626\u0632\u06cc\u0634-n-\u06a9\u06d2-l-\u06cc\u06d2-rewbwaus",level:3},{value:"\u06a9\u06cc \u06a9\u06cc \u06a9\u06cc t t t tt \u062a \u06a9\u06d2 \u06cc \u06a9\u06d2 \u06a9\u06d2 \u06a9\u06d2 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638",id:"\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-t-t-t-tt-\u062a-\u06a9\u06d2-\u06cc-\u06a9\u06d2-\u06a9\u06d2-\u06a9\u06d2-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638",level:3},{value:"\u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u06a9\u06cc \u06a9 \u06a9 \u06a9 \u06a9 \u06af\u06cc \u06af\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc",id:"\u062d\u0642\u06cc\u0642\u06cc-\u062d\u0642\u06cc\u0642\u06cc-\u062d\u0642\u06cc\u0642\u06cc-\u06a9\u06cc-\u06a9-\u06a9-\u06a9-\u06a9-\u06af\u06cc-\u06af\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc",level:2},{value:"b \u06cc\u0686 \u067e rwsausna \u06af \u0627\u0648\u0627\u0648\u0631\u0633 \u0627\u0650\u0646\u06af\u0631\u0646\u0633 \u0634\u06cc\u0688\u0648\u0644\u0646",id:"b-\u06cc\u0686-\u067e-rwsausna-\u06af-\u0627\u0648\u0627\u0648\u0631\u0633-\u0627\u0650\u0646\u06af\u0631\u0646\u0633-\u0634\u06cc\u0688\u0648\u0644\u0646",level:3},{value:"\u0645\u0648\u0645\u0648\u0631 \u06cc \u0645\u0648\u0646\u06c1\u0648\u0646 \u0679",id:"\u0645\u0648\u0645\u0648\u0631-\u06cc-\u0645\u0648\u0646\u06c1\u0648\u0646-\u0679",level:3},{value:"ros 2 an \u0636 \u0645\u0645\u0627\u0645",id:"ros-2-an-\u0636-\u0645\u0645\u0627\u0645",level:2},{value:"vla nwad n \u0641 aa \u0630",id:"vla-nwad-n-\u0641-aa-\u0630",level:3},{value:"vla asn \u0633\u0631\u0648\u0631",id:"vla-asn-\u0633\u0631\u0648\u0631",level:3},{value:"\u062d\u0642\u06cc\u0642\u06cc \u062f\u0646\u06cc\u0627 \u06a9\u06cc \u0627\u0639\u0627\u0628\u0631\u0627\u0628\u0628\u06cc\u0633\u0633 \u0633\u0646\u0628\u0627\u0644\u0646\u0627",id:"\u062d\u0642\u06cc\u0642\u06cc-\u062f\u0646\u06cc\u0627-\u06a9\u06cc-\u0627\u0639\u0627\u0628\u0631\u0627\u0628\u0628\u06cc\u0633\u0633-\u0633\u0646\u0628\u0627\u0644\u0646\u0627",level:2},{value:"\u0628\u06c1\u062a \u0632\u06cc\u0627\u062f\u06c1 - \u0633\u0646\u0633\u0631 \u06ccswr",id:"\u0628\u06c1\u062a-\u0632\u06cc\u0627\u062f\u06c1---\u0633\u0646\u0633\u0631-\u06ccswr",level:3},{value:"\u0639\u0645\u0627\u0644\u06c1 \u0648\u0648\u0631\u06a9 \u0627\u0650\u0633",id:"\u0639\u0645\u0627\u0644\u06c1-\u0648\u0648\u0631\u06a9-\u0627\u0650\u0633",level:2},{value:"\u062e LAA \u0635\u06c1",id:"\u062e-laa-\u0635\u06c1",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"itt-\u06c1-3-vla-an-\u0636-\u0645\u0645\u0627\u0645",children:"itt \u06c1 3: vla an \u0636 \u0645\u0645\u0627\u0645"})}),"\n",(0,t.jsx)(n.h2,{id:"\u062c-a-\u062c",children:"\u062c a \u062c"}),"\n",(0,t.jsx)(n.p,{children:"\u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u060c \u060c \u060c \u060c \u06c1 \u06c1 \u06c1 \u060c \u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc"}),"\n",(0,t.jsx)(n.h2,{id:"ss-\u06cc\u06a9\u06be-n-\u06d2-\u06a9\u06d2-maua-\u0635-d",children:"ss \u06cc\u06a9\u06be n \u06d2 \u06a9\u06d2 maua \u0635 d"}),"\n",(0,t.jsx)(n.p,{children:"\u06a9\u06d2 \u0630 \u06a9 \u06a9 \u06a9 \u06a9 a/\u06a9\u06cc \u06a9\u06cc \u062e \u062e \u062e \u062e atatam \u06a9 a \u06cc\u06c1 \u06cc\u06c1 \u06c1\u0641 \u06c1\u0641 \u0622\u067e \u0622\u067e \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06a9 \u06d2 \u06d2 \u06d2 \u06d2 \u06af \u06af \u06af \u06af \u06af"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u062a\u0650\u0679 .\u0646 \u06a9 r \u06cc\u06ba"}),"\n",(0,t.jsx)(n.li,{children:"\u0628\u06c1\u062a\u0631 \u0648\u0642\u062a \u06a9\u06cc \u06a9\u0627\u0631\u06a9\u0631\u062f\u06af\u06cc \u06a9\u0648 \u0628\u06c1\u062a\u0631 \u0628\u0646\u0627\u0626\u06cc\u06ba"}),"\n",(0,t.jsx)(n.li,{children:"\u0639\u0646\u0627\u0636\u0645\u0627\u0645 \u0639\u06a9"}),"\n",(0,t.jsx)(n.li,{children:"\u062d\u0642\u06cc\u0642\u06cc inda \u06cc a \u06a9\u06cc \u062e aamauch \u06a9 o snanbaul \u06cc\u06ba\u06d4 vla ttaidat \u06cc"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"vla-maa-\u0688-l-\u06a9\u06cc-taia-\u06cc-nat-\u06cc",children:"vla maa \u0688 l \u06a9\u06cc taia \u06cc nat \u06cc"}),"\n",(0,t.jsx)(n.h3,{id:"maa-\u0688-l-\u0622\u067e\u0679\u06cc-maa-\u0626\u0632\u06cc\u0634-n-\u06a9\u06d2-l-\u06cc\u06d2-rewbwaus",children:"maa \u0688 l \u0622\u067e\u0679\u06cc maa \u0626\u0632\u06cc\u0634 n \u06a9\u06d2 l \u06cc\u06d2 rewbwaus"}),"\n",(0,t.jsx)(n.p,{children:"\u0648\u0650\u0644 \u06a9\u06cc \u062a\u0639 \u0628\u0644\u06a9\u06c1"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import torch\r\nimport torch_tensorrt\r\n\r\nclass OptimizedVLA:\r\n    def __init__(self, original_model, device='cuda'):\r\n        self.device = device\r\n        \r\n        # Convert model \u06a9\u0648 evaluation mode \u0627\u0648\u0631 optimize\r\n        self.model = original_model.eval()\r\n        \r\n        # Optimize \u06a9\u06d2 \u0633\u0627\u062a\u06be TensorRT\r\n        self.model_optimized = self.optimize_with_tensorrt()\r\n    \r\n    def optimize_with_tensorrt(self):\r\n        # Convert \u06a9\u0627/\u06a9\u06cc model \u06a9\u0648 TensorRT optimized format\r\n        optimized_model = torch_tensorrt.compile(\r\n            self.model,\r\n            inputs=[\r\n                torch_tensorrt.Input((1, 3, 224, 224)),  # Image input\r\n                torch_tensorrt.Input((1, 512))          # Text embedding\r\n            ],\r\n            enabled_precisions={torch.float, torch.int8}\r\n        )\r\n        return optimized_model\r\n    \r\n    def predict(self, image, text_embedding):\r\n        \u06a9\u06d2 \u0633\u0627\u062a\u06be torch.no_grad():\r\n            # Run optimized inference\r\n            \u0627\u06cc\u06a9\u0634\u0646 = self.model_optimized, \r\n                                         text_embedding.\u06a9\u0648(self.device))\r\n        return \u0627\u06cc\u06a9\u0634\u0646.cpu()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-t-t-t-tt-\u062a-\u06a9\u06d2-\u06cc-\u06a9\u06d2-\u06a9\u06d2-\u06a9\u06d2-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638-\u062d\u0641\u0638",children:"\u06a9\u06cc \u06a9\u06cc \u06a9\u06cc t t t tt \u062a \u06a9\u06d2 \u06cc \u06a9\u06d2 \u06a9\u06d2 \u06a9\u06d2 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638 \u062d\u0641\u0638"}),"\n",(0,t.jsx)(n.p,{children:"l \u06a9\u06d2 l \u06cc\u06d2 \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u062a \u062a \u0622 \u0622 \u0622 \u0622 \u067e \u067e \u067e \u067e \u067e \u067e \u067e \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641 \u0641"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import onnx\r\nimport onnxruntime \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 ort\r\n\r\nclass EdgeVLA:\r\n    def __init__(self, onnx_model_path):\r\n        # Load ONNX model \u06a9\u06d2 \u0644\u06cc\u06d2 edge deployment\r\n        self.session = ort.InferenceSession(\r\n            onnx_model_path,\r\n            providers=['TensorrtExecutionProvider', \r\n                      'CUDAExecutionProvider', \r\n                      'CPUExecutionProvider']\r\n        )\r\n    \r\n    def predict(self, image, text_embedding):\r\n        # Prepare inputs \u0645\u06cc\u06ba ONNX format\r\n        input_feed = {\r\n            'image': image.numpy(),\r\n            'text_embedding': text_embedding.numpy()\r\n        }\r\n        \r\n        # Run inference\r\n        outputs = self.session.run(None, input_feed)\r\n        \r\n        return torch.from_numpy(outputs[0])\r\n    \r\n    def optimize_for_jetson(self):\r\n        # Special optimizations \u06a9\u06d2 \u0644\u06cc\u06d2 NVIDIA Jetson platforms\r\n        pass\n"})}),"\n",(0,t.jsx)(n.h2,{id:"\u062d\u0642\u06cc\u0642\u06cc-\u062d\u0642\u06cc\u0642\u06cc-\u062d\u0642\u06cc\u0642\u06cc-\u06a9\u06cc-\u06a9-\u06a9-\u06a9-\u06a9-\u06af\u06cc-\u06af\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc-\u06a9\u06cc",children:"\u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u062d\u0642\u06cc\u0642\u06cc \u06a9\u06cc \u06a9 \u06a9 \u06a9 \u06a9 \u06af\u06cc \u06af\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc"}),"\n",(0,t.jsx)(n.h3,{id:"b-\u06cc\u0686-\u067e-rwsausna-\u06af-\u0627\u0648\u0627\u0648\u0631\u0633-\u0627\u0650\u0646\u06af\u0631\u0646\u0633-\u0634\u06cc\u0688\u0648\u0644\u0646",children:"b \u06cc\u0686 \u067e rwsausna \u06af \u0627\u0648\u0627\u0648\u0631\u0633 \u0627\u0650\u0646\u06af\u0631\u0646\u0633 \u0634\u06cc\u0688\u0648\u0644\u0646"}),"\n",(0,t.jsx)(n.p,{children:"vla tt \u062e\u0641\u06cc\u0641 \u06a9 \u06a9 v v \u0628\u06c1\u0627\u062a\u0631 \u0628\u0648\u0646\u0627 \u06a9\u06d2 l \u06cc\u06d2 l \u06cc\u06d2 realtimetimate roobwauss:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import asyncio\r\nimport queue\r\nimport threading\r\n\u0633\u06d2 collections import deque\r\n\r\nclass RealTimeVLA:\r\n    def __init__(self, model, max_batch_size=4):\r\n        self.model = model\r\n        self.max_batch_size = max_batch_size\r\n        \r\n        # Queues \u06a9\u06d2 \u0644\u06cc\u06d2 input \u0627\u0648\u0631 output\r\n        self.input_queue = queue.Queue()\r\n        self.output_queue = queue.Queue()\r\n        \r\n        # Buffer \u06a9\u06d2 \u0644\u06cc\u06d2 batching\r\n        self.batch_buffer = deque(maxlen=max_batch_size)\r\n        \r\n        # Start processing thread\r\n        self.processing_thread = threading.Thread(target=self.process_loop)\r\n        self.processing_thread.daemon = True\r\n        self.processing_thread.start()\r\n    \r\n    def submit_request(self, image, text_command):\r\n        request = {\r\n            'image': image,\r\n            'text_command': text_command,\r\n            'timestamp': time.time()\r\n        }\r\n        self.input_queue.put(request)\r\n    \r\n    def get_prediction(self, timeout=1.0):\r\n        try:\r\n            return self.output_queue.get(timeout=timeout)\r\n        except queue.Empty:\r\n            return None\r\n    \r\n    def process_loop(self):\r\n        \u062c\u0628 \u062a\u06a9 True:\r\n            # Wait \u06a9\u06d2 \u0644\u06cc\u06d2 inputs\r\n            \u0627\u06af\u0631 \u0646\u06c1\u06cc\u06ba self.input_queue.empty():\r\n                request = self.input_queue.get()\r\n                self.batch_buffer.append(request)\r\n            \r\n            # Process \u06a9\u0628 we \u0631\u06a9\u06be\u062a\u06d2 \u06c1\u06cc\u06ba enough samples \u06cc\u0627 timeout\r\n            \u0627\u06af\u0631 (len(self.batch_buffer) >= self.max_batch_size \u06cc\u0627 \r\n                 self.batch_buffer[0]['timestamp'] > 0.1)):  # 100ms timeout\r\n                \r\n                batch = list(self.batch_buffer)\r\n                self.batch_buffer.clear()\r\n                \r\n                # Process batch\r\n                images = torch.stack\r\n                texts = [req['text_command'] \u06a9\u06d2 \u0644\u06cc\u06d2 req \u0645\u06cc\u06ba batch]\r\n                \r\n                # Run inference\r\n                \u06a9\u06d2 \u0633\u0627\u062a\u06be torch.no_grad():\r\n                    \u0627\u06cc\u06a9\u0634\u0646\u0632 = self.model(images, texts)\r\n                \r\n                # Return results\r\n                \u06a9\u06d2 \u0644\u06cc\u06d2 \u0645\u06cc\u06ba, \u0627\u06cc\u06a9\u0634\u0646 \u0645\u06cc\u06ba enumerate(\u0627\u06cc\u06a9\u0634\u0646\u0632):\r\n                    result = {\r\n                        '\u0627\u06cc\u06a9\u0634\u0646': \u0627\u06cc\u06a9\u0634\u0646,\r\n                        'request': batch[\u0645\u06cc\u06ba]\r\n                    }\r\n                    self.output_queue.put(result)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"\u0645\u0648\u0645\u0648\u0631-\u06cc-\u0645\u0648\u0646\u06c1\u0648\u0646-\u0679",children:"\u0645\u0648\u0645\u0648\u0631 \u06cc \u0645\u0648\u0646\u06c1\u0648\u0646 \u0679"}),"\n",(0,t.jsx)(n.p,{children:"\u0645\u0648\u0648\u0633\u0631 \u0645\u0627\u06c1\u0645\u0648\u0631\u06cc \u06a9 a \u06a9 asatamal \u06a9\u06d2 l \u06cc\u06d2 l \u06cc\u06d2 msslsl vla -ila -archn:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import gc\r\nimport psutil\r\n\u0633\u06d2 torch.cuda import memory_reserved, memory_allocated\r\n\r\nclass MemoryEfficientVLA:\r\n    def __init__(self, model):\r\n        self.model = model\r\n        self.max_memory_usage = 0.8 * psutil.virtual_memory().total\r\n        self.cache = {}  # \u06a9\u06d2 \u0644\u06cc\u06d2 caching intermediate results\r\n    \r\n    def predict_with_memory_management(self, image, text_command):\r\n        # Check memory usage \u067e\u06c1\u0644\u06d2 processing\r\n        self.cleanup_memory_if_needed()\r\n        \r\n        # Make prediction\r\n        \u06a9\u06d2 \u0633\u0627\u062a\u06be torch.no_grad():\r\n            \u0627\u06cc\u06a9\u0634\u0646 = self.model(image, text_command)\r\n        \r\n        return \u0627\u06cc\u06a9\u0634\u0646\r\n    \r\n    def cleanup_memory_if_needed(self):\r\n        # Check \u0633\u0633\u0679\u0645 memory usage\r\n        \u0627\u06af\u0631 psutil.virtual_memory().percent > 80:\r\n            # Clear cache\r\n            self.cache.clear()\r\n            \r\n            # Clear CUDA cache\r\n            \u0627\u06af\u0631 torch.cuda.is_available():\r\n                torch.cuda.empty_cache()\r\n            \r\n            # Force garbage collection\r\n            gc.collect()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"ros-2-an-\u0636-\u0645\u0645\u0627\u0645",children:"ros 2 an \u0636 \u0645\u0645\u0627\u0645"}),"\n",(0,t.jsx)(n.h3,{id:"vla-nwad-n-\u0641-aa-\u0630",children:"vla nwad n \u0641 aa \u0630"}),"\n",(0,t.jsx)(n.p,{children:"ROS ROS 2 NOVAU \u06a9\u06d2 LLA VLA MAA \u0688 L AN \u0636 Mamam \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc \u06a9\u06cc"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import rclpy\r\n\u0633\u06d2 rclpy.\u0646\u0648\u062f import \u0646\u0648\u062f\r\n\u0633\u06d2 sensor_msgs.msg import Image\r\n\u0633\u06d2 std_msgs.msg import String\r\n\u0633\u06d2 geometry_msgs.msg import Twist\r\n\u0633\u06d2 your_msgs.msg import VLAAction  # Custom message type\r\nimport message_filters\r\n\u0633\u06d2 cv_bridge import CvBridge\r\n\r\nclass VLAROSNode:\r\n    def __init__(self):\r\n        super().__init__('vla_ros_node')\r\n        \r\n        # Initialize VLA model\r\n        self.vla_model = self.load_optimized_vla_model()\r\n        \r\n        # \u062a\u0631\u062a\u06cc\u0628 ROS 2 interfaces\r\n        self.bridge = CvBridge()\r\n        \r\n        # Subscribe \u06a9\u0648 image \u0627\u0648\u0631 \u06a9\u0645\u0627\u0646\u0688 \u0679\u0627\u067e\u06a9\u0633\r\n        self.image_sub = message_filters.\u0633\u0628\u0633\u06a9\u0631\u0627\u0626\u06cc\u0628\u0631(self, Image, '/camera/image_raw')\r\n        self.command_sub = message_filters.\u0633\u0628\u0633\u06a9\u0631\u0627\u0626\u06cc\u0628\u0631(self, String, '/vla_command')\r\n        \r\n        # Synchronize image \u0627\u0648\u0631 \u06a9\u0645\u0627\u0646\u0688 messages\r\n        self.ts = message_filters.ApproximateTimeSynchronizer(\r\n            [self.image_sub, self.command_sub], \r\n            queue_size=10, \r\n            slop=0.1\r\n        )\r\n        self.ts.registerCallback(self.vla_callback)\r\n        \r\n        # \u067e\u0628\u0644\u0634\u0631 \u06a9\u06d2 \u0644\u06cc\u06d2 VLA \u0627\u06cc\u06a9\u0634\u0646\u0632\r\n        self.action_pub = self.create_publisher(VLAAction, '/vla_action', 10)\r\n        \r\n        # \u067e\u0628\u0644\u0634\u0631 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0631\u0648\u0628\u0648\u0679 commands\r\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\r\n    \r\n    def load_optimized_vla_model(self):\r\n        # Load \u0622\u067e \u06a9\u0627 optimized VLA model \u06cc\u06c1\u0627\u06ba\r\n        pass\r\n    \r\n    def vla_callback(self, image_msg, command_msg):\r\n        # Convert ROS image \u06a9\u0648 tensor\r\n        cv_image = self.bridge.imgmsg_to_cv2(image_msg, desired_encoding='rgb8')\r\n        image_tensor = self.preprocess_image(cv_image)\r\n        \r\n        # Process \u06a9\u0645\u0627\u0646\u0688\r\n        \u06a9\u0645\u0627\u0646\u0688 = command_msg.data\r\n        \r\n        # Get \u0627\u06cc\u06a9\u0634\u0646 \u0633\u06d2 VLA model\r\n        \u0627\u06cc\u06a9\u0634\u0646 = self.vla_model\r\n        \r\n        # Publish \u0627\u06cc\u06a9\u0634\u0646\r\n        action_msg = self.create_vla_action_msg\r\n        self.action_pub.publish(action_msg)\r\n        \r\n        # Convert \u06a9\u0648 \u0631\u0648\u0628\u0648\u0679 \u06a9\u0645\u0627\u0646\u0688 \u0627\u06af\u0631 needed\r\n        robot_cmd = self.vla_action_to_robot_cmd(action_msg)\r\n        self.cmd_vel_pub.publish(robot_cmd)\r\n    \r\n    def preprocess_image(self, cv_image):\r\n        # Preprocess image \u06a9\u06d2 \u0644\u06cc\u06d2 VLA model\r\n        pass\r\n    \r\n    def create_vla_action_msg:\r\n        # Create VLAAction message \u0633\u06d2 model output\r\n        pass\r\n    \r\n    def vla_action_to_robot_cmd(self, vla_action):\r\n        # Convert VLA \u0627\u06cc\u06a9\u0634\u0646 \u06a9\u0648 \u0631\u0648\u0628\u0648\u0679 \u06a9\u0645\u0627\u0646\u0688 (e.g., Twist)\r\n        pass\n"})}),"\n",(0,t.jsx)(n.h3,{id:"vla-asn-\u0633\u0631\u0648\u0631",children:"vla asn \u0633\u0631\u0648\u0631"}),"\n",(0,t.jsx)(n.p,{children:"\u06cc\u06a9 \u0627\u0650\u0646 \u0633\u0631\u0648\u0631 \u06a9\u06d2 \u0644\u0650\u0644 \u0650 \u0645\u0650\u0645\u0644 \u06a9 \u0645\u0650\u0645\u0627\u0644 \u06a9 \u0645\u0650\u0645\u0644 \u06a9 \u0645\u0650\u0645\u0644 \u06a9 \u0645\u0650\u0633\u0645\u0648\u0633\u0645\u0648 \u0627\u0644\u0627 \u0627\u0644\u0627 \u0627\u0644\u0627\u0648\u062d\u0648 \u0627\u0648\u0633\u0648 \u0627\u0648\u0646\u0648\u0633 -"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"\u0633\u06d2 rclpy.\u0627\u06cc\u06a9\u0634\u0646 import ActionServer, GoalResponse, CancelResponse\r\n\u0633\u06d2 your_msgs.\u0627\u06cc\u06a9\u0634\u0646 import VLATask  # Custom \u0627\u06cc\u06a9\u0634\u0646 type\r\nimport threading\r\n\r\nclass VLAActionServer:\r\n    def __init__(self):\r\n        super().__init__('vla_action_server')\r\n        \r\n        # Initialize VLA model\r\n        self.vla_model = self.load_vla_model()\r\n        \r\n        # \u062a\u0631\u062a\u06cc\u0628 \u0627\u06cc\u06a9\u0634\u0646 server\r\n        self._action_server = ActionServer(\r\n            self,\r\n            VLATask,\r\n            'vla_task',\r\n            execute_callback=self.execute_callback,\r\n            goal_callback=self.goal_callback,\r\n            cancel_callback=self.cancel_callback\r\n        )\r\n        \r\n        # Current task tracking\r\n        self._is_task_active = False\r\n        self._current_task = None\r\n    \r\n    def goal_callback(self, goal_request):\r\n        \u0627\u06af\u0631 self._is_task_active:\r\n            return GoalResponse.REJECT\r\n        else:\r\n            return GoalResponse.ACCEPT\r\n    \r\n    def cancel_callback(self, goal_handle):\r\n        return CancelResponse.ACCEPT\r\n    \r\n    async def execute_callback(self, goal_handle):\r\n        self.get_logger().info('Executing VLA task...')\r\n        \r\n        # Mark task \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 active\r\n        self._is_task_active = True\r\n        self._current_task = goal_handle\r\n        \r\n        feedback_msg = VLATask.Feedback()\r\n        result_msg = VLATask.Result()\r\n        \r\n        try:\r\n            # Execute \u06a9\u0627/\u06a9\u06cc VLA task\r\n            success = await self.execute_vla_task(\r\n                goal_handle.request.instruction,\r\n                goal_handle.request.target_object\r\n            )\r\n            \r\n            \u0627\u06af\u0631 success:\r\n                result_msg.success = True\r\n                goal_handle.succeed()\r\n            else:\r\n                result_msg.success = False\r\n                goal_handle.abort()\r\n                \r\n        except Exception \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 e:\r\n            self.get_logger().error(f'VLA task failed: {str(e)}')\r\n            result_msg.success = False\r\n            goal_handle.abort()\r\n        finally:\r\n            self._is_task_active = False\r\n            self._current_task = None\r\n        \r\n        return result_msg\r\n    \r\n    async def execute_vla_task(self, instruction, target_object):\r\n        # Execute \u0627\u06cc\u06a9 complete VLA task\r\n        # \u06cc\u06c1 _MAYBE_ involve multiple steps\r\n        import asyncio\r\n        \r\n        # Step 1: Navigate \u06a9\u0648 object\r\n        nav_success = await self.navigate_to_object(target_object)\r\n        \u0627\u06af\u0631 \u0646\u06c1\u06cc\u06ba nav_success:\r\n            return False\r\n        \r\n        # Step 2: Identify \u0627\u0648\u0631 understand object\r\n        object_info = await self.get_object_info(target_object)\r\n        \r\n        # Step 3: Execute manipulation task\r\n        manipulation_success = await self.execute_manipulation(instruction, object_info)\r\n        \r\n        return manipulation_success\n"})}),"\n",(0,t.jsx)(n.h2,{id:"\u062d\u0642\u06cc\u0642\u06cc-\u062f\u0646\u06cc\u0627-\u06a9\u06cc-\u0627\u0639\u0627\u0628\u0631\u0627\u0628\u0628\u06cc\u0633\u0633-\u0633\u0646\u0628\u0627\u0644\u0646\u0627",children:"\u062d\u0642\u06cc\u0642\u06cc \u062f\u0646\u06cc\u0627 \u06a9\u06cc \u0627\u0639\u0627\u0628\u0631\u0627\u0628\u0628\u06cc\u0633\u0633 \u0633\u0646\u0628\u0627\u0644\u0646\u0627"}),"\n",(0,t.jsx)(n.h3,{id:"\u0628\u06c1\u062a-\u0632\u06cc\u0627\u062f\u06c1---\u0633\u0646\u0633\u0631-\u06ccswr",children:"\u0628\u06c1\u062a \u0632\u06cc\u0627\u062f\u06c1 - \u0633\u0646\u0633\u0631 \u06ccswr"}),"\n",(0,t.jsx)(n.p,{children:"\u0648\u0650\u0644 \u0627\u0650\u0633\u0633\u0633\u0644 \u0627\u0644\u0633\u0633\u0645\u0645\u0627 \u0644\u0650\u0644\u0632 \u0644\u0650\u0644\u0632 \u0645\u06cc\u0628\u0648 \u060c"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class RobustVLA:\r\n    def __init__(self, base_model):\r\n        self.base_model = base_model\r\n        self.noise_augmentation = self.setup_noise_augmentation()\r\n    \r\n    def setup_noise_augmentation(self):\r\n        # \u062a\u0631\u062a\u06cc\u0628 \u06a9\u06d2 \u0644\u06cc\u06d2 adding synthetic noise \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 inference\r\n        return {\r\n            'gaussian_noise': {'mean': 0.0, 'std': 0.01},\r\n            'dropout_rate': 0.1,\r\n            'color_jitter': {'brightness': 0.2, 'contrast': 0.2}\r\n        }\r\n    \r\n    def add_noise_robustness(self, image):\r\n        # Add noise \u06a9\u0648 input \u06a9\u0648 make model \u0645\u0632\u06cc\u062f robust\r\n        import torchvision.transforms \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 transforms\r\n        \r\n        transform = transforms.Compose([\r\n            transforms.ColorJitter(\r\n                brightness=self.noise_augmentation['color_jitter']['brightness'],\r\n                contrast=self.noise_augmentation['color_jitter']['contrast']\r\n            ),\r\n            transforms.GaussianBlur(kernel_size=3),\r\n        ])\r\n        \r\n        # Add noise \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 inference\r\n        \u0627\u06af\u0631 self.training \u06cc\u0627 random.random() < 0.3:  # 30% \u06a9\u0627 \u06a9\u0627/\u06a9\u06cc time\r\n            noisy_image = transform(image)\r\n        else:\r\n            noisy_image = image\r\n            \r\n        return noisy_image\r\n    \r\n    def predict_robust(self, image, text_command):\r\n        # Add noise \u06a9\u06d2 \u0644\u06cc\u06d2 robustness\r\n        robust_image = self.add_noise_robustness(image)\r\n        \r\n        # Make prediction\r\n        \u0627\u06cc\u06a9\u0634\u0646 = self.base_model(robust_image, text_command)\r\n        \r\n        return \u0627\u06cc\u06a9\u0634\u0646\n"})}),"\n",(0,t.jsx)(n.h3,{id:""}),"\n",(0,t.jsx)(n.p,{children:"\u063a\u06cc r \u06cc\u0642\u06cc n \u06cc \u06cc urataaal \u06a9\u06cc \u0645\u0648\u0688\u0631"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 np\r\n\r\nclass UncertaintyAwareVLA:\r\n    def __init__(self, base_model, num_samples=10):\r\n        self.base_model = base_model\r\n        self.num_samples = num_samples\r\n        \r\n        # Enable dropout \u06a9\u06d2 \u0644\u06cc\u06d2 uncertainty estimation\r\n        self.enable_dropout()\r\n    \r\n    def enable_dropout(self):\r\n        """Enable dropout \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 inference \u06a9\u06d2 \u0644\u06cc\u06d2 uncertainty estimation"""\r\n        def apply_dropout(m):\r\n            \u0627\u06af\u0631 type(m) == nn.Dropout:\r\n                m.train()\r\n        self.base_model.apply(apply_dropout)\r\n    \r\n    def predict_with_uncertainty(self, image, text_command):\r\n        # Monte Carlo sampling \u06a9\u06d2 \u0644\u06cc\u06d2 uncertainty estimation\r\n        predictions = []\r\n        \r\n        \u06a9\u06d2 \u0644\u06cc\u06d2 _ \u0645\u06cc\u06ba range(self.num_samples):\r\n            pred = self.base_model(image, text_command)\r\n            predictions.append(pred.detach().cpu().numpy())\r\n        \r\n        predictions = np.array(predictions)\r\n        \r\n        # Calculate mean \u0627\u0648\u0631 uncertainty\r\n        mean_pred = np.mean(predictions, axis=0)\r\n        uncertainty = np.std(predictions, axis=0)\r\n        \r\n        return {\r\n            \'mean_action\': torch.from_numpy(mean_pred),\r\n            \'uncertainty\': torch.from_numpy(uncertainty),\r\n            \'confidence\': 1.0 / (1.0 + uncertainty)  # Higher confidence = lower uncertainty\r\n        }\r\n    \r\n    def should_delegate_to_safety(self, uncertainty, threshold=0.5):\r\n        """Check \u0627\u06af\u0631 uncertainty \u06c1\u06d2 too \u0627\u0648\u0646\u0686\u0627 \u0627\u0648\u0631 \u0686\u0627\u06c1\u06cc\u06d2 defer \u06a9\u0648 safety \u0633\u0633\u0679\u0645"""\r\n        return np.max(uncertainty) > threshold\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\u0639\u0645\u0627\u0644\u06c1-\u0648\u0648\u0631\u06a9-\u0627\u0650\u0633",children:"\u0639\u0645\u0627\u0644\u06c1 \u0648\u0648\u0631\u06a9 \u0627\u0650\u0633"}),"\n",(0,t.jsx)(n.p,{children:"\u06c1\u0641 \u06c1\u0641 t \u06c1 s vr \u06a9 sassis maus \u06cc\u06a9 vla maa \u0688 l \u06a9 v murboau \u0637 aaml \u06c1\u06d2 Saati sati saat \u06be \u06be rebotic ssssaum:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{}),"\n",(0,t.jsx)(n.li,{}),"\n",(0,t.jsx)(n.li,{}),"\n",(0,t.jsx)(n.li,{children:"\u0679\u06cc s \u0679 \u06a9 a/\u06a9\u06cc ssasm \u06a9\u06d2 scaat \u06be a \u0635 li ssancr"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\u062e-laa-\u0635\u06c1",children:"\u062e LAA \u0635\u06c1"}),"\n",(0,t.jsx)(n.p,{children:"\u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06c1\u0641 \u06a9 a/\u06a9\u06cc \u06a9\u06cc \u06a9\u06cc umamam \u06a9 a waussw waussl ala ala ala \u06d2 \u06d2 \u06d2 \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u06cc \u0688 \u0688 \u06cc \u06cc \u06cc \u06cc \u06cc n \u0688 ln \u06af \u06af \u062d\u0642\u06cc\u0642\u06cc \u0633\u0648\u0633\u0648\u0644 '\u0633\u0648\u0633\u0627 \u0627\u06cc\u0633 \u0627\u06cc\u0633 \u0627\u0633\u0679\u0627\u0626\u06cc \u06cc"})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>i});var a=r(6540);const t={},s=a.createContext(t);function l(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);