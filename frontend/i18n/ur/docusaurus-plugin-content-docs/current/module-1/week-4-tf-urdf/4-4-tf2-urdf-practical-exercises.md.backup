---

sidebar_position: 4

---



# 4.4: Practical Exercises - TF2 and URDF Integration

## Overview

This submodule provides hands-on exercises to apply TF2 and URDF concepts in realistic robotic scenarios. You'll build complete systems that integrate both technologies, working with real sensor data, robot models, and spatial transformations.

## Learning Objectives

By the end of this submodule, you will:
- Build a complete robot model with sensors using URDF
- Integrate TF2 with robot state publishing
- Process and transform real sensor data using TF2
- Debug TF tree issues in complex robot systems
- Create a complete navigation-ready robot model
- Apply performance optimization techniques

## Exercise 1: Building a Complete Robot Model

### Objective
Create a complete URDF model for a mobile robot with multiple sensors and implement the supporting launch files.

### Step 1: Create the Package Structure

First, create a new ROS 2 package for our robot model:

```bash
cd ~/ros2_ws/src
ros2 pkg create --build-type ament_python robot_model_exercises
```

### Step 2: Create the URDF Model

Create the file `robot_model_exercises/urdf/exercise_robot.urdf.xacro`:

```xml
<?xml version="1.0"?>
<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="exercise_robot">
  
  <!-- Properties -->
  <xacro:property name="M_PI" value="3.1415926535897931"/>
  <xacro:property name="base_width" value="0.6"/>
  <xacro:property name="base_length" value="0.8"/>
  <xacro:property name="base_height" value="0.3"/>
  <xacro:property name="wheel_radius" value="0.15"/>
  <xacro:property name="wheel_width" value="0.08"/>
  <xacro:property name="wheel_mass" value="2.0"/>
  <xacro:property name="base_mass" value="50.0"/>
  <xacro:property name="caster_radius" value="0.05"/>
  
  <!-- Materials -->
  <material name="black">
    <color rgba="0.0 0.0 0.0 1.0"/>
  </material>
  
  <material name="blue">
    <color rgba="0.0 0.0 0.8 1.0"/>
  </material>
  
  <material name="red">
    <color rgba="0.8 0.0 0.0 1.0"/>
  </material>
  
  <material name="white">
    <color rgba="1.0 1.0 1.0 1.0"/>
  </material>
  
  <!-- Base link -->
  <link name="base_link">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <box size="${base_length} ${base_width} ${base_height}"/>
      </geometry>
      <material name="blue"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <box size="${base_length} ${base_width} ${base_height}"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="${base_mass}"/>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <inertia ixx="5.0" ixy="0.0" ixz="0.0" iyy="5.0" iyz="0.0" izz="10.0"/>
    </inertial>
  </link>
  
  <!-- Base footprint -->
  <link name="base_footprint">
    <visual>
      <geometry>
        <cylinder radius="0.01" length="0.001"/>
      </geometry>
      <material name="white"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0.01" rpy="0 0 0"/>
      <geometry>
        <cylinder radius="${base_width/2}" length="0.02"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="0.0001"/>
      <inertia ixx="0.0001" ixy="0.0" ixz="0.0" iyy="0.0001" iyz="0.0" izz="0.0001"/>
    </inertial>
  </link>
  
  <!-- Joint: base_footprint to base_link -->
  <joint name="base_footprint_joint" type="fixed">
    <parent link="base_footprint"/>
    <child link="base_link"/>
    <origin xyz="0 0 ${base_height/2}" rpy="0 0 0"/>
  </joint>
  
  <!-- Macro for wheels -->
  <xacro:macro name="wheel" params="prefix reflect">
    <link name="${prefix}_wheel_link">
      <visual>
        <origin xyz="0 0 0" rpy="${M_PI/2} 0 0"/>
        <geometry>
          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>
        </geometry>
        <material name="black"/>
      </visual>
      
      <collision>
        <origin xyz="0 0 0" rpy="${M_PI/2} 0 0"/>
        <geometry>
          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>
        </geometry>
      </collision>
      
      <inertial>
        <mass value="${wheel_mass}"/>
        <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.2"/>
      </inertial>
    </link>
    
    <joint name="${prefix}_wheel_joint" type="continuous">
      <parent link="base_link"/>
      <child link="${prefix}_wheel_link"/>
      <origin xyz="${base_length/2 - wheel_width/2} ${reflect * (base_width/2 + wheel_width/2)} -${base_height/2}" rpy="0 0 0"/>
      <axis xyz="0 1 0"/>
    </joint>
  </xacro:macro>
  
  <!-- Create wheels -->
  <xacro:wheel prefix="front_left" reflect="1"/>
  <xacro:wheel prefix="front_right" reflect="-1"/>
  <xacro:wheel prefix="rear_left" reflect="1"/>
  <xacro:wheel prefix="rear_right" reflect="-1"/>
  
  <!-- Front caster wheel -->
  <link name="front_caster_link">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <sphere radius="${caster_radius}"/>
      </geometry>
      <material name="black"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <sphere radius="${caster_radius}"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="0.5"/>
      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.001"/>
    </inertial>
  </link>
  
  <joint name="front_caster_joint" type="continuous">
    <parent link="base_link"/>
    <child link="front_caster_link"/>
    <origin xyz="${base_length/2 - caster_radius} 0 -${base_height/2 + caster_radius}" rpy="0 0 0"/>
    <axis xyz="0 0 1"/>
  </joint>
  
  <!-- Rear caster wheel -->
  <link name="rear_caster_link">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <sphere radius="${caster_radius}"/>
      </geometry>
      <material name="black"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <sphere radius="${caster_radius}"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="0.5"/>
      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.001"/>
    </inertial>
  </link>
  
  <joint name="rear_caster_joint" type="continuous">
    <parent link="base_link"/>
    <child link="rear_caster_link"/>
    <origin xyz="-${base_length/2 + caster_radius} 0 -${base_height/2 + caster_radius}" rpy="0 0 0"/>
    <axis xyz="0 0 1"/>
  </joint>
  
  <!-- Sensor mount plate -->
  <link name="sensor_mount_plate">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <box size="0.2 0.2 0.02"/>
      </geometry>
      <material name="white"/>
    </visual>
    
    <inertial>
      <mass value="0.5"/>
      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.002"/>
    </inertial>
  </link>
  
  <joint name="sensor_mount_joint" type="fixed">
    <parent link="base_link"/>
    <child link="sensor_mount_plate"/>
    <origin xyz="${base_length/2 - 0.1} 0 ${base_height/2 + 0.01}" rpy="0 0 0"/>
  </joint>
  
  <!-- RGB-D Camera -->
  <link name="camera_link">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <box size="0.05 0.1 0.03"/>
      </geometry>
      <material name="black"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <box size="0.05 0.1 0.03"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="0.1"/>
      <inertia ixx="0.0001" ixy="0.0" ixz="0.0" iyy="0.0001" iyz="0.0" izz="0.0001"/>
    </inertial>
  </link>
  
  <joint name="camera_joint" type="fixed">
    <parent link="sensor_mount_plate"/>
    <child link="camera_link"/>
    <origin xyz="0.025 0 0.025" rpy="0 0 0"/>
  </joint>
  
  <!-- LIDAR -->
  <link name="lidar_link">
    <visual>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <cylinder radius="0.05" length="0.05"/>
      </geometry>
      <material name="red"/>
    </visual>
    
    <collision>
      <origin xyz="0 0 0" rpy="0 0 0"/>
      <geometry>
        <cylinder radius="0.05" length="0.05"/>
      </geometry>
    </collision>
    
    <inertial>
      <mass value="0.3"/>
      <inertia ixx="0.0001" ixy="0.0" ixz="0.0" iyy="0.0001" iyz="0.0" izz="0.0002"/>
    </inertial>
  </link>
  
  <joint name="lidar_joint" type="fixed">
    <parent link="sensor_mount_plate"/>
    <child link="lidar_link"/>
    <origin xyz="0.05 0 0.05" rpy="0 0 0"/>
  </joint>
  
  <!-- IMU -->
  <link name="imu_link">
    <inertial>
      <mass value="0.01"/>
      <inertia ixx="0.0001" ixy="0.0" ixz="0.0" iyy="0.0001" iyz="0.0" izz="0.0001"/>
    </inertial>
  </link>
  
  <joint name="imu_joint" type="fixed">
    <parent link="base_link"/>
    <child link="imu_link"/>
    <origin xyz="0 0 ${base_height/4}" rpy="0 0 0"/>
  </joint>
  
</robot>
```

### Step 3: Update Package Files

Update `robot_model_exercises/package.xml`:

```xml
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>robot_model_exercises</name>
  <version>0.1.0</version>
  <description>Practical exercises for TF2 and URDF integration</description>
  <maintainer email="user@example.com">User</maintainer>
  <license>Apache-2.0</license>

  <depend>rclpy</depend>
  <depend>std_msgs</depend>
  <depend>geometry_msgs</depend>
  <depend>sensor_msgs</depend>
  <depend>nav_msgs</depend>
  <depend>tf2_ros</depend>
  <depend>tf2_geometry_msgs</depend>
  <depend>tf_transformations</depend>

  <buildtool_depend>ament_python</buildtool_depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>
```

Update `robot_model_exercises/setup.py`:

```python
from setuptools import setup
from glob import glob
import os

package_name = 'robot_model_exercises'

setup(
    name=package_name,
    version='0.1.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
        # Include URDF files
        (os.path.join('share', package_name, 'urdf'), glob('urdf/*.urdf.xacro')),
        # Include launch files
        (os.path.join('share', package_name, 'launch'), glob('launch/*.py')),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='User',
    maintainer_email='user@example.com',
    description='Practical exercises for TF2 and URDF integration',
    license='Apache-2.0',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            'sensor_transformer = robot_model_exercises.sensor_transformer:main',
            'tf_visualizer = robot_model_exercises.tf_visualizer:main',
            'robot_state_publisher = robot_model_exercises.robot_state_publisher:main',
        ],
    },
)
```

## Exercise 2: Sensor Data Transformation

### Objective
Create a node that subscribes to sensor data and transforms it between coordinate frames using TF2.

Create `robot_model_exercises/robot_model_exercises/sensor_transformer.py`:

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan, PointCloud2
from geometry_msgs.msg import PointStamped, TransformStamped
from tf2_ros import TransformListener, Buffer
from tf2_ros import TransformException
from tf2_geometry_msgs import do_transform_points
from rclpy.qos import QoSProfile
import numpy as np
import math
from sensor_msgs_py import point_cloud2
from sensor_msgs.msg import PointField

class SensorTransformer(Node):
    def __init__(self):
        super().__init__('sensor_transformer')
        
        # Create a transform buffer
        self.tf_buffer = Buffer()
        
        # Create a transform listener
        self.tf_listener = TransformListener(self.tf_buffer, self)
        
        # Create QoS profile
        qos = QoSProfile(depth=10)
        
        # Subscribe to laser scan
        self.scan_sub = self.create_subscription(
            LaserScan, 'scan', self.scan_callback, qos)
        
        # Subscribe to point cloud (if available)
        self.pc_sub = self.create_subscription(
            PointCloud2, 'point_cloud', self.point_cloud_callback, qos)
        
        # Publishers for transformed data
        self.transformed_scan_pub = self.create_publisher(
            LaserScan, 'scan_in_base_link', qos)
        self.transformed_point_pub = self.create_publisher(
            PointStamped, 'transformed_point', qos)
        
        # Timer for periodic frame checking
        self.timer = self.create_timer(1.0, self.check_frames)
        
        self.get_logger().info('Sensor transformer node started')

    def scan_callback(self, msg):
        """Transform laser scan from sensor frame to base_link frame"""
        try:
            # Look up transform from lidar frame to base_link
            transform = self.tf_buffer.lookup_transform(
                'base_link',      # Target frame
                msg.header.frame_id,  # Source frame
                msg.header.stamp,     # Time of the scan
                timeout=rclpy.duration.Duration(seconds=1.0))
            
            # Transform the laser scan
            transformed_scan = LaserScan()
            transformed_scan.header.stamp = self.get_clock().now().to_msg()
            transformed_scan.header.frame_id = 'base_link'
            transformed_scan.angle_min = msg.angle_min
            transformed_scan.angle_max = msg.angle_max
            transformed_scan.angle_increment = msg.angle_increment
            transformed_scan.time_increment = msg.time_increment
            transformed_scan.scan_time = msg.scan_time
            transformed_scan.range_min = msg.range_min
            transformed_scan.range_max = msg.range_max
            transformed_scan.ranges = msg.ranges
            transformed_scan.intensities = msg.intensities if msg.intensities else []
            
            # Publish the transformed scan
            self.transformed_scan_pub.publish(transformed_scan)
            
            # Log the transformation
            self.get_logger().info(
                f'Transformed scan from {msg.header.frame_id} to base_link')
            
        except TransformException as ex:
            self.get_logger().warn(f'Could not transform scan: {ex}')

    def point_cloud_callback(self, msg):
        """Transform point cloud from sensor frame to base_link frame"""
        try:
            # Look up transform
            transform = self.tf_buffer.lookup_transform(
                'base_link',
                msg.header.frame_id,
                msg.header.stamp,
                timeout=rclpy.duration.Duration(seconds=1.0))
            
            # Extract points from PointCloud2
            points = []
            for point in point_cloud2.read_points(msg, field_names=("x", "y", "z"), skip_nans=True):
                points.append([point[0], point[1], point[2], 1.0])  # Format for transformation
            
            # Convert to homogeneous coordinates if needed
            points_array = np.array(points).T
            
            # Create transformation matrix from TF transform
            t = transform.transform.translation
            r = transform.transform.rotation
            
            # Create 4x4 transformation matrix
            transform_matrix = np.eye(4)
            # Translation
            transform_matrix[0, 3] = t.x
            transform_matrix[1, 3] = t.y
            transform_matrix[2, 3] = t.z
            
            # Rotation (quaternion to matrix)
            qw, qx, qy, qz = r.w, r.x, r.y, r.z
            # Convert quaternion to rotation matrix
            transform_matrix[0, 0] = 1 - 2*(qy*qy + qz*qz)
            transform_matrix[0, 1] = 2*(qx*qy - qw*qz)
            transform_matrix[0, 2] = 2*(qx*qz + qw*qy)
            transform_matrix[1, 0] = 2*(qx*qy + qw*qz)
            transform_matrix[1, 1] = 1 - 2*(qx*qx + qz*qz)
            transform_matrix[1, 2] = 2*(qy*qz - qw*qx)
            transform_matrix[2, 0] = 2*(qx*qz - qw*qy)
            transform_matrix[2, 1] = 2*(qy*qz + qw*qx)
            transform_matrix[2, 2] = 1 - 2*(qx*qx + qy*qy)
            
            # Transform points
            transformed_points = transform_matrix @ points_array
            
            # Log transformation result
            self.get_logger().info(
                f'Transformed point cloud with {len(points)} points from {msg.header.frame_id} to base_link')
            
        except TransformException as ex:
            self.get_logger().warn(f'Could not transform point cloud: {ex}')
        except Exception as e:
            self.get_logger().warn(f'Point cloud transformation failed: {e}')

    def check_frames(self):
        """Periodically check if all required frames exist"""
        required_frames = [
            'base_link', 'base_footprint', 'lidar_link', 
            'camera_link', 'imu_link'
        ]
        
        missing_frames = []
        for frame in required_frames:
            try:
                # Check if frame exists by looking up transform to itself in the past
                self.tf_buffer.lookup_transform(frame, frame, rclpy.time.Time(), 
                                               timeout=rclpy.duration.Duration(seconds=0.1))
            except:
                missing_frames.append(frame)
        
        if missing_frames:
            self.get_logger().warn(f'Missing frames: {missing_frames}')
        else:
            self.get_logger().info('All required frames are available')

def main(args=None):
    rclpy.init(args=args)
    node = SensorTransformer()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info('Shutting down sensor transformer...')
    finally:
        node.destroy_node()
        rclpy.shutdown()
```

## Exercise 3: TF Visualization and Analysis

Create `robot_model_exercises/robot_model_exercises/tf_visualizer.py`:

```python
import rclpy
from rclpy.node import Node
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Point
from tf2_ros import Buffer, TransformListener
from tf2_ros import TransformException
from rclpy.qos import QoSProfile
import math

class TFVisualizer(Node):
    def __init__(self):
        super().__init__('tf_visualizer')
        
        # Create TF buffer and listener
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)
        
        # Create publisher for visualization markers
        qos = QoSProfile(depth=10)
        self.marker_pub = self.create_publisher(MarkerArray, 'tf_visualization_markers', qos)
        
        # Timer to periodically update visualization
        self.timer = self.create_timer(0.5, self.update_visualization)
        
        self.get_logger().info('TF Visualizer started')

    def update_visualization(self):
        """Update visualization of TF tree"""
        try:
            # Get all available frames
            all_frames = self.tf_buffer.all_frames_as_string()
            
            # Create marker array
            marker_array = MarkerArray()
            
            # Create a marker for each transform
            frame_names = [name.split(' ')[0] for name in all_frames.split('\n') if name]
            frame_names = [name for name in frame_names if name]  # Remove empty strings
            
            # Create axes for each frame
            for i, frame in enumerate(frame_names):
                try:
                    # Get transform from base_link to this frame
                    t = self.tf_buffer.lookup_transform(
                        'base_link', frame, rclpy.time.Time())
                    
                    # Create axis markers
                    self.add_frame_axes(marker_array, t, frame, i)
                except TransformException:
                    # If can't transform to base_link, skip this frame
                    continue
            
            # Publish the marker array
            self.marker_pub.publish(marker_array)
            
        except Exception as e:
            self.get_logger().warn(f'Error updating visualization: {e}')

    def add_frame_axes(self, marker_array, transform, frame_name, frame_id):
        """Add coordinate axes visualization for a frame"""
        # X-axis (red)
        x_axis_marker = Marker()
        x_axis_marker.header.frame_id = 'base_link'
        x_axis_marker.header.stamp = self.get_clock().now().to_msg()
        x_axis_marker.ns = f"x_axis_{frame_name}"
        x_axis_marker.id = frame_id * 3
        x_axis_marker.type = Marker.ARROW
        x_axis_marker.action = Marker.ADD
        
        # Set start point to transform origin
        start_point = Point()
        start_point.x = transform.transform.translation.x
        start_point.y = transform.transform.translation.y
        start_point.z = transform.transform.translation.z
        
        # Set end point to be along x-axis
        end_point = Point()
        end_point.x = start_point.x + 0.1  # 10cm along x-axis
        end_point.y = start_point.y
        end_point.z = start_point.z
        
        x_axis_marker.points = [start_point, end_point]
        x_axis_marker.scale.x = 0.01  # Shaft diameter
        x_axis_marker.scale.y = 0.02  # Head diameter
        x_axis_marker.color.r = 1.0
        x_axis_marker.color.g = 0.0
        x_axis_marker.color.b = 0.0
        x_axis_marker.color.a = 1.0
        
        marker_array.markers.append(x_axis_marker)
        
        # Y-axis (green)
        y_axis_marker = Marker()
        y_axis_marker.header.frame_id = 'base_link'
        y_axis_marker.header.stamp = self.get_clock().now().to_msg()
        y_axis_marker.ns = f"y_axis_{frame_name}"
        y_axis_marker.id = frame_id * 3 + 1
        y_axis_marker.type = Marker.ARROW
        y_axis_marker.action = Marker.ADD
        
        start_point = Point()
        start_point.x = transform.transform.translation.x
        start_point.y = transform.transform.translation.y
        start_point.z = transform.transform.translation.z
        
        end_point = Point()
        end_point.x = start_point.x
        end_point.y = start_point.y + 0.1  # 10cm along y-axis
        end_point.z = start_point.z
        
        y_axis_marker.points = [start_point, end_point]
        y_axis_marker.scale.x = 0.01
        y_axis_marker.scale.y = 0.02
        y_axis_marker.color.r = 0.0
        y_axis_marker.color.g = 1.0
        y_axis_marker.color.b = 0.0
        y_axis_marker.color.a = 1.0
        
        marker_array.markers.append(y_axis_marker)
        
        # Z-axis (blue)
        z_axis_marker = Marker()
        z_axis_marker.header.frame_id = 'base_link'
        z_axis_marker.header.stamp = self.get_clock().now().to_msg()
        z_axis_marker.ns = f"z_axis_{frame_name}"
        z_axis_marker.id = frame_id * 3 + 2
        z_axis_marker.type = Marker.ARROW
        z_axis_marker.action = Marker.ADD
        
        start_point = Point()
        start_point.x = transform.transform.translation.x
        start_point.y = transform.transform.translation.y
        start_point.z = transform.transform.translation.z
        
        end_point = Point()
        end_point.x = start_point.x
        end_point.y = start_point.y
        end_point.z = start_point.z + 0.1  # 10cm along z-axis
        
        z_axis_marker.points = [start_point, end_point]
        z_axis_marker.scale.x = 0.01
        z_axis_marker.scale.y = 0.02
        z_axis_marker.color.r = 0.0
        z_axis_marker.color.g = 0.0
        z_axis_marker.color.b = 1.0
        z_axis_marker.color.a = 1.0
        
        marker_array.markers.append(z_axis_marker)

    def get_tf_tree_info(self):
        """Get information about the TF tree structure"""
        try:
            tree_info = self.tf_buffer.all_frames_as_yaml()
            self.get_logger().info(f'TF Tree:\n{tree_info}')
            
            # Identify root frame
            all_frames = self.tf_buffer.all_frames_as_string()
            self.get_logger().info(f'Available frames: {all_frames}')
            
        except Exception as e:
            self.get_logger().error(f'Error getting TF tree info: {e}')

def main(args=None):
    rclpy.init(args=args)
    node = TFVisualizer()
    
    # Run tree info once at startup
    node.get_tf_tree_info()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info('Shutting down TF visualizer...')
    finally:
        node.destroy_node()
        rclpy.shutdown()
```

## Exercise 4: Robot State Publisher with Sensor Integration

Create `robot_model_exercises/robot_model_exercises/robot_state_publisher.py`:

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
from nav_msgs.msg import Odometry
from geometry_msgs.msg import TransformStamped
from tf2_ros import TransformBroadcaster
from std_msgs.msg import Header
from rclpy.qos import QoSProfile
import math
import numpy as np

class ExerciseRobotStatePublisher(Node):
    def __init__(self):
        super().__init__('exercise_robot_state_publisher')
        
        # Create transform broadcaster
        self.tf_broadcaster = TransformBroadcaster(self)
        
        # Create QoS profile
        qos = QoSProfile(depth=10)
        
        # Subscribe to joint states (from simulated or real robot)
        self.joint_sub = self.create_subscription(
            JointState, 'joint_states', self.joint_callback, qos)
        
        # Subscribe to odometry (if available)
        self.odom_sub = self.create_subscription(
            Odometry, 'odom', self.odom_callback, qos)
        
        # Publishers for joint states (if needed for simulation)
        self.joint_pub = self.create_publisher(JointState, 'joint_states', qos)
        
        # Timer for publishing state
        self.timer = self.create_timer(0.02, self.publish_robot_states)  # 50 Hz
        
        # Robot state variables
        self.wheel_positions = {
            'front_left_wheel_joint': 0.0,
            'front_right_wheel_joint': 0.0,
            'rear_left_wheel_joint': 0.0,
            'rear_right_wheel_joint': 0.0
        }
        
        self.caster_positions = {
            'front_caster_joint': 0.0,
            'rear_caster_joint': 0.0
        }
        
        # Robot pose from odometry
        self.x = 0.0
        self.y = 0.0
        self.theta = 0.0
        
        # Simulate robot movement
        self.sim_time = 0.0
        
        self.get_logger().info('Exercise Robot State Publisher started')

    def joint_callback(self, msg):
        """Update joint positions from joint state messages"""
        for i, name in enumerate(msg.name):
            if name in self.wheel_positions:
                self.wheel_positions[name] = msg.position[i]
            elif name in self.caster_positions:
                self.caster_positions[name] = msg.position[i]

    def odom_callback(self, msg):
        """Update robot pose from odometry"""
        self.x = msg.pose.pose.position.x
        self.y = msg.pose.pose.position.y
        
        # Convert quaternion to yaw
        q = msg.pose.pose.orientation
        siny_cosp = 2 * (q.w * q.z + q.x * q.y)
        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)
        self.theta = math.atan2(siny_cosp, cosy_cosp)

    def publish_robot_states(self):
        """Publish robot states including transforms"""
        # Simulate wheel motion
        self.sim_time += 0.02  # Increment simulation time
        
        # Update wheel positions based on simulated motion
        wheel_velocity = 1.0  # rad/s
        for joint_name in self.wheel_positions:
            self.wheel_positions[joint_name] += wheel_velocity * 0.02
            if 'right' in joint_name:  # Right wheels rotate opposite for forward motion
                self.wheel_positions[joint_name] -= 2 * wheel_velocity * 0.02
        
        # Update caster positions
        for joint_name in self.caster_positions:
            self.caster_positions[joint_name] = math.sin(self.sim_time) * 0.5  # Oscillating
        
        # Move robot in a square pattern
        linear_vel = 0.5  # m/s
        current_seg = int(self.sim_time / 5) % 4  # 5 seconds per side
        seg_time = self.sim_time % 5
        
        if current_seg == 0:  # Moving in +X direction
            self.x += linear_vel * 0.02
        elif current_seg == 1:  # Moving in +Y direction
            self.y += linear_vel * 0.02
        elif current_seg == 2:  # Moving in -X direction
            self.x -= linear_vel * 0.02
        else:  # Moving in -Y direction
            self.y -= linear_vel * 0.02
        
        # Publish joint states (if needed for other nodes)
        self.publish_joint_states()
        
        # Publish transforms
        self.publish_transforms()

    def publish_joint_states(self):
        """Publish joint state messages"""
        msg = JointState()
        msg.name = []
        msg.position = []
        msg.velocity = []
        msg.effort = []
        
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.header.frame_id = 'joint_states'
        
        # Add wheel joints
        for joint_name, position in self.wheel_positions.items():
            msg.name.append(joint_name)
            msg.position.append(position)
            msg.velocity.append(1.0)  # Simulated velocity
            msg.effort.append(0.0)
        
        # Add caster joints
        for joint_name, position in self.caster_positions.items():
            msg.name.append(joint_name)
            msg.position.append(position)
            msg.velocity.append(0.5)  # Simulated velocity
            msg.effort.append(0.0)
        
        self.joint_pub.publish(msg)

    def publish_transforms(self):
        """Publish all static and dynamic transforms"""
        # Transform from odom to base_footprint (simulating odometry)
        t = TransformStamped()
        t.header.stamp = self.get_clock().now().to_msg()
        t.header.frame_id = 'odom'
        t.child_frame_id = 'base_footprint'
        
        t.transform.translation.x = self.x
        t.transform.translation.y = self.y
        t.transform.translation.z = 0.0
        
        # Convert theta to quaternion
        from tf_transformations import quaternion_from_euler
        q = quaternion_from_euler(0, 0, self.theta)
        t.transform.rotation.x = q[0]
        t.transform.rotation.y = q[1]
        t.transform.rotation.z = q[2]
        t.transform.rotation.w = q[3]
        
        self.tf_broadcaster.sendTransform(t)
        
        # Transform from base_footprint to base_link (fixed offset)
        t2 = TransformStamped()
        t2.header.stamp = self.get_clock().now().to_msg()
        t2.header.frame_id = 'base_footprint'
        t2.child_frame_id = 'base_link'
        
        t2.transform.translation.x = 0.0
        t2.transform.translation.y = 0.0
        t2.transform.translation.z = 0.15  # base_height/2 = 0.3/2
        
        t2.transform.rotation.x = 0.0
        t2.transform.rotation.y = 0.0
        t2.transform.rotation.z = 0.0
        t2.transform.rotation.w = 1.0
        
        self.tf_broadcaster.sendTransform(t2)
        
        # Transform for each wheel (dynamic based on joint positions)
        wheel_transforms = [
            ('front_left_wheel_joint', 'base_link', 'front_left_wheel_link', 0.35, 0.35, -0.15),
            ('front_right_wheel_joint', 'base_link', 'front_right_wheel_link', 0.35, -0.35, -0.15),
            ('rear_left_wheel_joint', 'base_link', 'rear_left_wheel_link', -0.35, 0.35, -0.15),
            ('rear_right_wheel_joint', 'base_link', 'rear_right_wheel_link', -0.35, -0.35, -0.15),
        ]
        
        for joint_name, parent_frame, child_frame, x, y, z in wheel_transforms:
            t = TransformStamped()
            t.header.stamp = self.get_clock().now().to_msg()
            t.header.frame_id = parent_frame
            t.child_frame_id = child_frame
            
            t.transform.translation.x = x
            t.transform.translation.y = y
            t.transform.translation.z = z
            
            # Rotate wheel based on joint position
            q_wheel = quaternion_from_euler(0, 0, self.wheel_positions[joint_name])
            t.transform.rotation.x = q_wheel[0]
            t.transform.rotation.y = q_wheel[1]
            t.transform.rotation.z = q_wheel[2]
            t.transform.rotation.w = q_wheel[3]
            
            self.tf_broadcaster.sendTransform(t)
        
        # Transform for caster wheels
        caster_transforms = [
            ('front_caster_joint', 'base_link', 'front_caster_link', 0.25, 0.0, -0.15),
            ('rear_caster_joint', 'base_link', 'rear_caster_link', -0.25, 0.0, -0.15),
        ]
        
        for joint_name, parent_frame, child_frame, x, y, z in caster_transforms:
            t = TransformStamped()
            t.header.stamp = self.get_clock().now().to_msg()
            t.header.frame_id = parent_frame
            t.child_frame_id = child_frame
            
            t.transform.translation.x = x
            t.transform.translation.y = y
            t.transform.translation.z = z
            
            # Rotate caster based on joint position
            q_caster = quaternion_from_euler(
                math.sin(self.caster_positions[joint_name]) * 0.1,
                math.cos(self.caster_positions[joint_name]) * 0.1,
                self.caster_positions[joint_name]
            )
            t.transform.rotation.x = q_caster[0]
            t.transform.rotation.y = q_caster[1]
            t.transform.rotation.z = q_caster[2]
            t.transform.rotation.w = q_caster[3]
            
            self.tf_broadcaster.sendTransform(t)

def main(args=None):
    rclpy.init(args=args)
    node = ExerciseRobotStatePublisher()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info('Shutting down robot state publisher...')
    finally:
        node.destroy_node()
        rclpy.shutdown()
```

## Exercise 5: Launch File and System Integration

Create the launch file `robot_model_exercises/launch/exercise_system_launch.py`:

```python
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.substitutions import Command, PathJoinSubstitution
from launch_ros.actions import Node
from launch_ros.substitutions import FindPackageShare

def generate_launch_description():
    # Declare arguments
    declared_arguments = []
    declared_arguments.append(
        DeclareLaunchArgument(
            'description_file',
            default_value='exercise_robot.urdf.xacro',
            description='URDF/XACRO description file with the robot'
        )
    )

    # Get URDF via xacro
    robot_description_content = Command(
        [
            PathJoinSubstitution([FindPackageShare("robot_model_exercises"), "urdf", "exercise_robot.urdf.xacro"])
        ]
    )
    robot_description = {"robot_description": robot_description_content}

    # Robot State Publisher (from ROS2)
    robot_state_publisher_node = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        output='both',
        parameters=[robot_description]
    )

    # Exercise Robot State Publisher (custom node for dynamic transforms)
    exercise_robot_state_publisher_node = Node(
        package='robot_model_exercises',
        executable='exercise_robot_state_publisher',
        name='exercise_robot_state_publisher',
        output='both'
    )

    # Sensor Transformer
    sensor_transformer_node = Node(
        package='robot_model_exercises',
        executable='sensor_transformer',
        name='sensor_transformer',
        output='both'
    )

    # TF Visualizer
    tf_visualizer_node = Node(
        package='robot_model_exercises',
        executable='tf_visualizer',
        name='tf_visualizer',
        output='both'
    )

    return LaunchDescription(
        declared_arguments + [
            robot_state_publisher_node,
            exercise_robot_state_publisher_node,
            sensor_transformer_node,
            tf_visualizer_node,
        ]
    )
```

## Exercise 6: System Testing and Validation

### Running the Complete System

1. **Build the package:**
```bash
cd ~/ros2_ws
colcon build --packages-select robot_model_exercises
source install/setup.bash
```

2. **Launch the complete system:**
```bash
ros2 launch robot_model_exercises exercise_system_launch.py
```

3. **Monitor the TF tree:**
```bash
# View TF tree
ros2 run tf2_tools view_frames

# Monitor TF transforms
ros2 run tf2_ros tf2_monitor

# Echo specific transforms
ros2 run tf2_ros tf2_echo base_link lidar_link
```

4. **Visualize in RViz:**
```bash
ros2 run rviz2 rviz2
```

In RViz:
- Add a RobotModel display and set "Robot Description" to "robot_description"
- Add a TF display to visualize all transforms
- Add a MarkerArray display to see the TF visualization from our node

## Exercise 7: Performance Optimization and Debugging

### Optimized Implementation

Create an optimized version with caching and performance considerations:

```python
# robot_model_exercises/robot_model_exercises/optimized_sensor_transformer.py
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan
from geometry_msgs.msg import PointStamped
from tf2_ros import TransformListener, Buffer
from tf2_ros import TransformException
from rclpy.qos import QoSProfile
import time
from collections import defaultdict

class OptimizedSensorTransformer(Node):
    def __init__(self):
        super().__init__('optimized_sensor_transformer')
        
        # Create a transform buffer with cache
        self.tf_buffer = Buffer(
            cache_time=rclpy.duration.Duration(seconds=10.0))  # 10s cache
        self.tf_listener = TransformListener(self.tf_buffer, self)
        
        # Create QoS profile
        qos = QoSProfile(depth=5)  # Reduce depth for performance
        
        # Subscribe to laser scan
        self.scan_sub = self.create_subscription(
            LaserScan, 'scan', self.scan_callback, qos)
        
        # Publisher for transformed data
        self.transformed_scan_pub = self.create_publisher(
            LaserScan, 'scan_in_base_link', qos)
        
        # Cache for transforms that don't change frequently
        self.transform_cache = {}
        self.cache_timeout = 0.1  # 100ms cache timeout
        
        # Statistics
        self.transform_count = 0
        self.cache_hits = 0
        
        # Timer for performance statistics
        self.stats_timer = self.create_timer(5.0, self.print_stats)
        
        self.get_logger().info('Optimized Sensor Transformer started')

    def scan_callback(self, msg):
        """Transform laser scan from sensor frame to base_link frame with optimization"""
        start_time = time.time()
        
        try:
            # Check cache first
            cache_key = f"{msg.header.frame_id}_to_base_link"
            
            if cache_key in self.transform_cache:
                cached_transform, timestamp = self.transform_cache[cache_key]
                current_time = self.get_clock().now().nanoseconds / 1e9
                
                if current_time - timestamp < self.cache_timeout:
                    self.cache_hits += 1
                    transform = cached_transform
                else:
                    # Cache expired, get fresh transform
                    transform = self.tf_buffer.lookup_transform(
                        'base_link', msg.header.frame_id, msg.header.stamp,
                        timeout=rclpy.duration.Duration(seconds=0.5))
                    # Update cache
                    self.transform_cache[cache_key] = (transform, current_time)
            else:
                # No cache entry, get fresh transform
                transform = self.tf_buffer.lookup_transform(
                    'base_link', msg.header.frame_id, msg.header.stamp,
                    timeout=rclpy.duration.Duration(seconds=0.5))
                # Add to cache
                current_time = self.get_clock().now().nanoseconds / 1e9
                self.transform_cache[cache_key] = (transform, current_time)
            
            # Transform the laser scan (simplified - in real implementation, 
            # you'd transform each point)
            transformed_scan = msg
            transformed_scan.header.frame_id = 'base_link'
            self.transformed_scan_pub.publish(transformed_scan)
            
            self.transform_count += 1
            
            # Log performance info periodically
            if self.transform_count % 100 == 0:
                end_time = time.time()
                self.get_logger().info(
                    f'Transform performance: {(end_time - start_time)*1000:.2f}ms, '
                    f'Cache hit rate: {self.cache_hits/max(1, self.transform_count):.2%}')
        
        except TransformException as ex:
            self.get_logger().warn(f'Could not transform scan: {ex}')
        except Exception as e:
            self.get_logger().error(f'Unexpected error in scan callback: {e}')

    def print_stats(self):
        """Print performance statistics"""
        cache_hit_rate = self.cache_hits / max(1, self.transform_count) if self.transform_count > 0 else 0
        self.get_logger().info(
            f'TF Performance Stats - Transforms: {self.transform_count}, '
            f'Cache Hits: {self.cache_hits}, '
            f'Cache Hit Rate: {cache_hit_rate:.2%}')

def main(args=None):
    rclpy.init(args=args)
    node = OptimizedSensorTransformer()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info('Shutting down optimized sensor transformer...')
    finally:
        node.destroy_node()
        rclpy.shutdown()
```

## Exercise 8: Troubleshooting Common Issues

### Debugging Script

Create a debugging script `robot_model_exercises/test/tf_debugger.py`:

```python
import rclpy
from rclpy.node import Node
from tf2_ros import Buffer, TransformListener
from std_msgs.msg import String
from rclpy.qos import QoSProfile

class TFDebugger(Node):
    def __init__(self):
        super().__init__('tf_debugger')
        
        # Create a transform buffer
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)
        
        # Publisher for debug messages
        qos = QoSProfile(depth=10)
        self.debug_pub = self.create_publisher(String, 'tf_debug_output', qos)
        
        # Timer to run debug checks
        self.timer = self.create_timer(2.0, self.run_debug_checks)
        
        self.get_logger().info('TF Debugger started')

    def run_debug_checks(self):
        """Run various TF-related diagnostic checks"""
        self.get_logger().info('--- TF Debug Report ---')
        
        # Check 1: List all available frames
        try:
            frames_yaml = self.tf_buffer.all_frames_as_yaml()
            self.get_logger().info(f'Available frames:\n{frames_yaml}')
        except Exception as e:
            self.get_logger().error(f'Error getting frames: {e}')
        
        # Check 2: Validate common transforms
        common_transforms = [
            ('base_link', 'base_footprint'),
            ('base_link', 'lidar_link'),
            ('base_link', 'camera_link'),
            ('odom', 'base_footprint'),
        ]
        
        for parent, child in common_transforms:
            try:
                self.tf_buffer.lookup_transform(parent, child, rclpy.time.Time())
                self.get_logger().info(f'✓ Transform {parent} -> {child} is available')
            except Exception as e:
                self.get_logger().warn(f'✗ Transform {parent} -> {child} is NOT available: {e}')
        
        # Check 3: Transform latency
        try:
            # Get the most recent transform to check timestamp
            transform = self.tf_buffer.lookup_transform('base_link', 'lidar_link', rclpy.time.Time())
            stamp = transform.header.stamp
            current_time = self.get_clock().now()
            
            latency = (current_time.nanoseconds - rclpy.time.Time.from_msg(stamp).nanoseconds) / 1e9
            self.get_logger().info(f'Transform latency for base_link->lidar_link: {latency:.3f}s')
        except Exception as e:
            self.get_logger().warn(f'Could not check transform latency: {e}')
        
        # Check 4: TF tree connections
        try:
            # Try to find path between common frames
            self.tf_buffer.lookup_transform('odom', 'lidar_link', rclpy.time.Time())
            self.get_logger().info('✓ Full path available: odom -> lidar_link')
        except Exception as e:
            self.get_logger().warn(f'✗ No full path from odom to lidar_link: {e}')
        
        self.get_logger().info('--- End TF Debug Report ---')

def main(args=None):
    rclpy.init(args=args)
    node = TFDebugger()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.get_logger().info('Shutting down TF debugger...')
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

## Summary

This practical exercise module covered:

1. **Complete robot model creation**: Building a sophisticated URDF model with multiple sensors and joints
2. **Sensor data transformation**: Implementing nodes that transform sensor data using TF2
3. **TF visualization**: Creating tools to visualize and analyze the TF tree
4. **Performance optimization**: Techniques for efficient TF usage in real-time systems
5. **System integration**: Combining all components into a complete system
6. **Debugging techniques**: Tools and methods for troubleshooting TF-related issues

You have now learned how to:
- Create complex robot models using URDF/Xacro
- Integrate TF2 with robot state publishing
- Transform sensor data between coordinate frames
- Optimize TF performance in robotics applications
- Debug common TF tree issues

These skills are essential for developing complex robotic applications that require accurate spatial reasoning and sensor fusion.

This completes the submodules for Week 4 of Module 1 on TF2 and URDF in ROS 2.